{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navigation\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will learn how to use the Unity ML-Agents environment for the first project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893).\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing some necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "import time\n",
    "from dqn_agent import Agent\n",
    "from collections import deque\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will start the environment!  **_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/Banana.app\"`\n",
    "- **Windows** (x86): `\"path/to/Banana_Windows_x86/Banana.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Banana_Windows_x86_64/Banana.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Banana_Linux/Banana.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Banana_Linux/Banana.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/Banana_Linux_NoVis/Banana.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/Banana_Linux_NoVis/Banana.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Banana.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Banana.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: BananaBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 37\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: discrete\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name=\"Banana_Windows_x86_64/Banana.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<unityagents.environment.UnityEnvironment at 0x2aabd429c70>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "The simulation contains a single agent that navigates a large environment.  At each time step, it has four actions at its disposal:\n",
    "- `0` - walk forward \n",
    "- `1` - walk backward\n",
    "- `2` - turn left\n",
    "- `3` - turn right\n",
    "\n",
    "The state space has `37` dimensions and contains the agent's velocity, along with ray-based perception of objects around agent's forward direction.  A reward of `+1` is provided for collecting a yellow banana, and a reward of `-1` is provided for collecting a blue banana. \n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 1\n",
      "Number of actions: 4\n",
      "States look like: [1.         0.         0.         0.         0.84408134 0.\n",
      " 0.         1.         0.         0.0748472  0.         1.\n",
      " 0.         0.         0.25755    1.         0.         0.\n",
      " 0.         0.74177343 0.         1.         0.         0.\n",
      " 0.25854847 0.         0.         1.         0.         0.09355672\n",
      " 0.         1.         0.         0.         0.31969345 0.\n",
      " 0.        ]\n",
      "States have length: 37\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents in the environment\n",
    "print('Number of agents:', len(env_info.agents))\n",
    "\n",
    "# number of actions\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Number of actions:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "state = env_info.vector_observations[0]\n",
    "print('States look like:', state)\n",
    "state_size = len(state)\n",
    "print('States have length:', state_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Once this cell is executed, you will watch the agent's performance, if it selects an action (uniformly) at random with each time step.  A window should pop up that allows you to observe the agent, as it moves through the environment.  \n",
    "\n",
    "Of course, as part of the project, you'll have to change the code so that the agent is able to use its experience to gradually choose better actions when interacting with the environment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 18.0\n"
     ]
    }
   ],
   "source": [
    "env_info = env.reset(train_mode=False)[brain_name] # reset the environment\n",
    "state = env_info.vector_observations[0]            # get the current state\n",
    "score = 0                                          # initialize the score\n",
    "while True:\n",
    "    action = int(agent.act(state, 0.))\n",
    "    #action = np.random.randint(action_size)        # select an action\n",
    "    env_info = env.step(int(action))[brain_name]        # send the action to the environment\n",
    "    next_state = env_info.vector_observations[0]   # get the next state\n",
    "    reward = env_info.rewards[0]                   # get the reward\n",
    "    done = env_info.local_done[0]                  # see if episode has finished\n",
    "    score += reward                                # update the score\n",
    "    state = next_state                             # roll over the state to next time step\n",
    "    if done:                                       # exit loop if episode finished\n",
    "        break\n",
    "    \n",
    "print(\"Score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. It's Your Turn!\n",
    "\n",
    "Now it's your turn to train your own agent to solve the environment!  When training the environment, set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approach\n",
    "\n",
    "I am taking the following approach:\n",
    "\n",
    "* Overall we use a deep Q network (DQN) to train the agent using reinforcement learning.\n",
    "\n",
    "* start with a simple DQN network and see if it is sufficient to solve the problem. The initial network I tried was a fully connected nn with sizes at each layer: start_size (input) -> 64 -> 128 -> action_size (out). But this model does not seem to be sufficiently rich. The score I got was moving around 10 while I think we should be able to move even higher.\n",
    "\n",
    "* Then I tried a few other network structure. In the end I converge to the one I am submitting which is sufficient to get to score of ~15. The network is state_size -> 64 -> 128 -> 128 -> 64 -> action_size.\n",
    "\n",
    "* Epsilon greedy algorithm is used, with esp started at 100%, decaying at 99.5% and floored at 1%.\n",
    "\n",
    "* Replay buffer is used. We store upt o 10,000 memory and from that we randomly select experiences of batch size 64\n",
    "\n",
    "* separately I have also tried to implement the following features to improve training:\n",
    "  * [Double DQN](https://arxiv.org/abs/1509.06461) where use the latest Q net to pick the best next action, but use the target Q net to evaluate the action. This is controlled by the ddqn parameter when initializing the agent.\n",
    "  * [Dueling](https://arxiv.org/abs/1511.06581) where we bifurcate the last layers of the network to separately predie the value function and the action specific adjustment on top. For the dueling we normalized the action output by the mean across actions. This is controlled by the dueling parameter when we initialize the agent.\n",
    "  * [Prioried Experience Replay](https://arxiv.org/abs/1511.05952) where we prioritize the experience of higher TD difference. I also implemented the importance sampling weights as well. But the current implementation is extremely slow and more work is needed to make it useful. For now this feature is not used.\n",
    "  \n",
    "* I tried different combinations of training methods, ie, with and with out DDQN and Dueling respectively. This gives me 4 combinations. I ran these 4 models 10x each and plot out the resulting scores. To my surprise there is no observable pick up in the training speed across these few methodologies. it's possible that the network I used is too simple to observe material differences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dqn(agent, n_episodes=1000, max_t=1000, eps_start=1.0, eps_end=0.01, eps_decay=0.995, filename=\"\"):\n",
    "    \"\"\"Deep Q-Learning.\n",
    "    \n",
    "    Params\n",
    "    ======\n",
    "        n_episodes (int): maximum number of training episodes\n",
    "        max_t (int): maximum number of timesteps per episode\n",
    "        eps_start (float): starting value of epsilon, for epsilon-greedy action selection\n",
    "        eps_end (float): minimum value of epsilon\n",
    "        eps_decay (float): multiplicative factor (per episode) for decreasing epsilon\n",
    "        filename (string): filename to save the model parameters\n",
    "    \"\"\"\n",
    "    high_score = -100\n",
    "    scores = []                        # list containing scores from each episode\n",
    "    scores_window = deque(maxlen=100)  # last 100 scores\n",
    "    eps = eps_start                    # initialize epsilon\n",
    "    times = deque(maxlen=100)\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        env_info = env.reset(train_mode=True)[brain_name]\n",
    "        state = env_info.vector_observations[0]\n",
    "        score = 0\n",
    "        time1 = time.time()\n",
    "        for t in range(max_t):\n",
    "            action = agent.act(state, eps)\n",
    "            env_info = env.step(int(action))[brain_name]\n",
    "            next_state = env_info.vector_observations[0]\n",
    "            reward = env_info.rewards[0]\n",
    "            done = env_info.local_done[0]\n",
    "            agent.step(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "            score += reward\n",
    "            if done:\n",
    "                break \n",
    "        time2 = time.time()\n",
    "        scores_window.append(score)       # save most recent score\n",
    "        scores.append(score)              # save most recent score\n",
    "        times.append(time2-time1)\n",
    "        eps = max(eps_end, eps_decay*eps) # decrease epsilon\n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}\\tAverage Time: {:.2f}\\tBest Score Saved: {:.2f}'.format(i_episode, np.mean(scores_window), np.mean(times),high_score), end=\"\")\n",
    "        if i_episode % 100 == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}\\tAverage Time: {:.2f}\\tBest Score Saved: {:.2f}'.format(i_episode, np.mean(scores_window), np.mean(times),high_score))\n",
    "        mean_score = np.mean(scores_window)\n",
    "        if mean_score>=high_score and mean_score > 10:\n",
    "            torch.save(agent.qnetwork_local.state_dict(), filename)\n",
    "            high_score = mean_score\n",
    "            \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model 1: Double DQN with Dueling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Agent 000:\n",
      "\n",
      "Episode 100\tAverage Score: 0.63\tAverage Time: 1.14\tBest Score Saved: -100.00\n",
      "Episode 200\tAverage Score: 3.29\tAverage Time: 1.15\tBest Score Saved: -100.00\n",
      "Episode 300\tAverage Score: 7.01\tAverage Time: 1.16\tBest Score Saved: -100.00\n",
      "Episode 400\tAverage Score: 10.67\tAverage Time: 1.17\tBest Score Saved: 10.7700\n",
      "Episode 500\tAverage Score: 13.48\tAverage Time: 1.16\tBest Score Saved: 13.51\n",
      "Episode 600\tAverage Score: 14.24\tAverage Time: 1.16\tBest Score Saved: 14.30\n",
      "Episode 700\tAverage Score: 15.28\tAverage Time: 1.15\tBest Score Saved: 15.30\n",
      "Episode 800\tAverage Score: 14.40\tAverage Time: 1.15\tBest Score Saved: 15.55\n",
      "Episode 900\tAverage Score: 15.44\tAverage Time: 1.14\tBest Score Saved: 15.55\n",
      "Episode 1000\tAverage Score: 14.90\tAverage Time: 1.15\tBest Score Saved: 15.78\n",
      "\n",
      "\n",
      "Agent 001:\n",
      "\n",
      "Episode 100\tAverage Score: 0.44\tAverage Time: 1.11\tBest Score Saved: -100.00\n",
      "Episode 200\tAverage Score: 3.66\tAverage Time: 1.13\tBest Score Saved: -100.00\n",
      "Episode 300\tAverage Score: 7.35\tAverage Time: 1.13\tBest Score Saved: -100.00\n",
      "Episode 400\tAverage Score: 10.29\tAverage Time: 1.14\tBest Score Saved: 10.3900\n",
      "Episode 500\tAverage Score: 13.65\tAverage Time: 1.14\tBest Score Saved: 13.50\n",
      "Episode 600\tAverage Score: 14.38\tAverage Time: 1.13\tBest Score Saved: 14.48\n",
      "Episode 700\tAverage Score: 14.82\tAverage Time: 1.15\tBest Score Saved: 15.17\n",
      "Episode 800\tAverage Score: 14.57\tAverage Time: 1.14\tBest Score Saved: 15.17\n",
      "Episode 900\tAverage Score: 14.63\tAverage Time: 1.15\tBest Score Saved: 15.17\n",
      "Episode 1000\tAverage Score: 16.13\tAverage Time: 1.15\tBest Score Saved: 16.08\n",
      "\n",
      "\n",
      "Agent 002:\n",
      "\n",
      "Episode 100\tAverage Score: 0.83\tAverage Time: 1.11\tBest Score Saved: -100.00\n",
      "Episode 200\tAverage Score: 4.17\tAverage Time: 1.13\tBest Score Saved: -100.00\n",
      "Episode 300\tAverage Score: 7.65\tAverage Time: 1.14\tBest Score Saved: -100.00\n",
      "Episode 400\tAverage Score: 10.93\tAverage Time: 1.15\tBest Score Saved: 11.0300\n",
      "Episode 500\tAverage Score: 13.28\tAverage Time: 1.15\tBest Score Saved: 13.19\n",
      "Episode 600\tAverage Score: 14.86\tAverage Time: 1.15\tBest Score Saved: 14.91\n",
      "Episode 700\tAverage Score: 15.28\tAverage Time: 1.15\tBest Score Saved: 15.27\n",
      "Episode 800\tAverage Score: 15.48\tAverage Time: 1.15\tBest Score Saved: 15.89\n",
      "Episode 900\tAverage Score: 14.83\tAverage Time: 1.15\tBest Score Saved: 15.89\n",
      "Episode 1000\tAverage Score: 15.13\tAverage Time: 1.15\tBest Score Saved: 15.89\n",
      "\n",
      "\n",
      "Agent 003:\n",
      "\n",
      "Episode 100\tAverage Score: 0.30\tAverage Time: 1.12\tBest Score Saved: -100.00\n",
      "Episode 200\tAverage Score: 2.46\tAverage Time: 1.13\tBest Score Saved: -100.00\n",
      "Episode 300\tAverage Score: 5.45\tAverage Time: 1.14\tBest Score Saved: -100.00\n",
      "Episode 400\tAverage Score: 8.99\tAverage Time: 1.14\tBest Score Saved: -100.00\n",
      "Episode 500\tAverage Score: 12.69\tAverage Time: 1.13\tBest Score Saved: 12.6700\n",
      "Episode 600\tAverage Score: 14.34\tAverage Time: 1.13\tBest Score Saved: 14.37\n",
      "Episode 700\tAverage Score: 13.53\tAverage Time: 1.12\tBest Score Saved: 14.39\n",
      "Episode 800\tAverage Score: 14.80\tAverage Time: 1.12\tBest Score Saved: 15.04\n",
      "Episode 900\tAverage Score: 15.47\tAverage Time: 1.12\tBest Score Saved: 15.64\n",
      "Episode 1000\tAverage Score: 15.83\tAverage Time: 1.12\tBest Score Saved: 15.75\n",
      "\n",
      "\n",
      "Agent 004:\n",
      "\n",
      "Episode 100\tAverage Score: 0.89\tAverage Time: 1.09\tBest Score Saved: -100.00\n",
      "Episode 200\tAverage Score: 3.77\tAverage Time: 1.11\tBest Score Saved: -100.00\n",
      "Episode 300\tAverage Score: 8.29\tAverage Time: 1.11\tBest Score Saved: -100.00\n",
      "Episode 400\tAverage Score: 10.92\tAverage Time: 1.12\tBest Score Saved: 10.9000\n",
      "Episode 500\tAverage Score: 12.54\tAverage Time: 1.12\tBest Score Saved: 12.67\n",
      "Episode 600\tAverage Score: 14.43\tAverage Time: 1.12\tBest Score Saved: 14.50\n",
      "Episode 700\tAverage Score: 14.93\tAverage Time: 1.12\tBest Score Saved: 14.84\n",
      "Episode 800\tAverage Score: 13.71\tAverage Time: 1.12\tBest Score Saved: 15.05\n",
      "Episode 900\tAverage Score: 15.09\tAverage Time: 1.12\tBest Score Saved: 15.38\n",
      "Episode 1000\tAverage Score: 15.11\tAverage Time: 1.12\tBest Score Saved: 15.38\n",
      "\n",
      "\n",
      "Agent 005:\n",
      "\n",
      "Episode 100\tAverage Score: 0.20\tAverage Time: 1.09\tBest Score Saved: -100.00\n",
      "Episode 200\tAverage Score: 3.45\tAverage Time: 1.11\tBest Score Saved: -100.00\n",
      "Episode 300\tAverage Score: 6.69\tAverage Time: 1.11\tBest Score Saved: -100.00\n",
      "Episode 400\tAverage Score: 10.33\tAverage Time: 1.12\tBest Score Saved: 10.3600\n",
      "Episode 500\tAverage Score: 13.11\tAverage Time: 1.12\tBest Score Saved: 13.15\n",
      "Episode 600\tAverage Score: 15.05\tAverage Time: 1.12\tBest Score Saved: 15.09\n",
      "Episode 700\tAverage Score: 15.45\tAverage Time: 1.16\tBest Score Saved: 15.56\n",
      "Episode 800\tAverage Score: 15.32\tAverage Time: 1.14\tBest Score Saved: 15.88\n",
      "Episode 900\tAverage Score: 15.96\tAverage Time: 1.14\tBest Score Saved: 15.92\n",
      "Episode 1000\tAverage Score: 15.44\tAverage Time: 1.15\tBest Score Saved: 16.05\n",
      "\n",
      "\n",
      "Agent 006:\n",
      "\n",
      "Episode 100\tAverage Score: 0.40\tAverage Time: 1.11\tBest Score Saved: -100.00\n",
      "Episode 200\tAverage Score: 2.73\tAverage Time: 1.10\tBest Score Saved: -100.00\n",
      "Episode 300\tAverage Score: 6.50\tAverage Time: 1.13\tBest Score Saved: -100.00\n",
      "Episode 400\tAverage Score: 8.93\tAverage Time: 1.11\tBest Score Saved: -100.00\n",
      "Episode 500\tAverage Score: 13.43\tAverage Time: 1.11\tBest Score Saved: 13.4200\n",
      "Episode 600\tAverage Score: 15.06\tAverage Time: 1.17\tBest Score Saved: 15.05\n",
      "Episode 700\tAverage Score: 15.44\tAverage Time: 1.16\tBest Score Saved: 15.59\n",
      "Episode 800\tAverage Score: 16.01\tAverage Time: 1.15\tBest Score Saved: 16.08\n",
      "Episode 900\tAverage Score: 16.43\tAverage Time: 1.14\tBest Score Saved: 16.76\n",
      "Episode 1000\tAverage Score: 16.38\tAverage Time: 1.15\tBest Score Saved: 16.76\n",
      "\n",
      "\n",
      "Agent 007:\n",
      "\n",
      "Episode 100\tAverage Score: 0.47\tAverage Time: 1.12\tBest Score Saved: -100.00\n",
      "Episode 200\tAverage Score: 2.77\tAverage Time: 1.14\tBest Score Saved: -100.00\n",
      "Episode 300\tAverage Score: 6.49\tAverage Time: 1.16\tBest Score Saved: -100.00\n",
      "Episode 400\tAverage Score: 10.27\tAverage Time: 1.15\tBest Score Saved: 10.2800\n",
      "Episode 500\tAverage Score: 11.92\tAverage Time: 1.14\tBest Score Saved: 11.97\n",
      "Episode 600\tAverage Score: 14.19\tAverage Time: 1.16\tBest Score Saved: 14.24\n",
      "Episode 700\tAverage Score: 13.89\tAverage Time: 1.17\tBest Score Saved: 14.64\n",
      "Episode 800\tAverage Score: 14.05\tAverage Time: 1.16\tBest Score Saved: 14.64\n",
      "Episode 900\tAverage Score: 14.44\tAverage Time: 1.15\tBest Score Saved: 14.64\n",
      "Episode 1000\tAverage Score: 15.68\tAverage Time: 1.16\tBest Score Saved: 15.74\n",
      "\n",
      "\n",
      "Agent 008:\n",
      "\n",
      "Episode 100\tAverage Score: 1.12\tAverage Time: 1.13\tBest Score Saved: -100.00\n",
      "Episode 200\tAverage Score: 4.14\tAverage Time: 1.13\tBest Score Saved: -100.00\n",
      "Episode 300\tAverage Score: 6.66\tAverage Time: 1.15\tBest Score Saved: -100.00\n",
      "Episode 400\tAverage Score: 10.53\tAverage Time: 1.15\tBest Score Saved: 10.4100\n",
      "Episode 500\tAverage Score: 13.68\tAverage Time: 1.16\tBest Score Saved: 13.73\n",
      "Episode 600\tAverage Score: 14.84\tAverage Time: 1.17\tBest Score Saved: 14.78\n",
      "Episode 700\tAverage Score: 15.43\tAverage Time: 1.16\tBest Score Saved: 15.48\n",
      "Episode 800\tAverage Score: 14.51\tAverage Time: 1.16\tBest Score Saved: 15.71\n",
      "Episode 900\tAverage Score: 14.68\tAverage Time: 1.18\tBest Score Saved: 15.71\n",
      "Episode 1000\tAverage Score: 15.58\tAverage Time: 1.16\tBest Score Saved: 15.83\n",
      "\n",
      "\n",
      "Agent 009:\n",
      "\n",
      "Episode 100\tAverage Score: 0.19\tAverage Time: 1.11\tBest Score Saved: -100.00\n",
      "Episode 200\tAverage Score: 3.07\tAverage Time: 1.13\tBest Score Saved: -100.00\n",
      "Episode 300\tAverage Score: 6.80\tAverage Time: 1.13\tBest Score Saved: -100.00\n",
      "Episode 400\tAverage Score: 9.79\tAverage Time: 1.14\tBest Score Saved: -100.00\n",
      "Episode 500\tAverage Score: 12.99\tAverage Time: 1.14\tBest Score Saved: 13.0700\n",
      "Episode 600\tAverage Score: 14.80\tAverage Time: 1.16\tBest Score Saved: 14.70\n",
      "Episode 700\tAverage Score: 15.36\tAverage Time: 1.16\tBest Score Saved: 15.55\n",
      "Episode 800\tAverage Score: 15.56\tAverage Time: 1.17\tBest Score Saved: 15.67\n",
      "Episode 900\tAverage Score: 14.83\tAverage Time: 1.16\tBest Score Saved: 15.96\n",
      "Episode 1000\tAverage Score: 16.07\tAverage Time: 1.16\tBest Score Saved: 16.19\n"
     ]
    }
   ],
   "source": [
    "# Double DQN with Dueling\n",
    "dddqn_scores = []\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"\\n\\nAgent {:03d}:\\n\".format(i))\n",
    "    agent = Agent(state_size=state_size, action_size=action_size, seed=i*100, ddqn=True, sampling_mode=\"Uniform\", dueling=True )\n",
    "    scores = dqn(agent, filename = \"dddqn{:03d}.pth\".format(i))\n",
    "    dddqn_scores.append(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model 2: Double DQN (no Dueling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Agent 000:\n",
      "\n",
      "Episode 100\tAverage Score: 0.26\tAverage Time: 0.99\tBest Score Saved: -100.00\n",
      "Episode 200\tAverage Score: 2.39\tAverage Time: 1.00\tBest Score Saved: -100.00\n",
      "Episode 300\tAverage Score: 7.04\tAverage Time: 1.01\tBest Score Saved: -100.00\n",
      "Episode 400\tAverage Score: 10.12\tAverage Time: 1.02\tBest Score Saved: 10.1600\n",
      "Episode 500\tAverage Score: 12.52\tAverage Time: 1.02\tBest Score Saved: 12.48\n",
      "Episode 600\tAverage Score: 14.19\tAverage Time: 1.02\tBest Score Saved: 14.19\n",
      "Episode 700\tAverage Score: 15.56\tAverage Time: 1.02\tBest Score Saved: 15.61\n",
      "Episode 800\tAverage Score: 15.34\tAverage Time: 1.02\tBest Score Saved: 16.13\n",
      "Episode 900\tAverage Score: 15.12\tAverage Time: 1.02\tBest Score Saved: 16.13\n",
      "Episode 1000\tAverage Score: 15.41\tAverage Time: 1.02\tBest Score Saved: 16.13\n",
      "\n",
      "\n",
      "Agent 001:\n",
      "\n",
      "Episode 100\tAverage Score: 0.72\tAverage Time: 0.99\tBest Score Saved: -100.00\n",
      "Episode 200\tAverage Score: 4.81\tAverage Time: 1.00\tBest Score Saved: -100.00\n",
      "Episode 300\tAverage Score: 8.27\tAverage Time: 1.01\tBest Score Saved: -100.00\n",
      "Episode 400\tAverage Score: 11.42\tAverage Time: 1.02\tBest Score Saved: 11.3500\n",
      "Episode 500\tAverage Score: 13.07\tAverage Time: 1.02\tBest Score Saved: 13.16\n",
      "Episode 600\tAverage Score: 14.21\tAverage Time: 1.03\tBest Score Saved: 14.32\n",
      "Episode 700\tAverage Score: 15.23\tAverage Time: 1.03\tBest Score Saved: 15.30\n",
      "Episode 800\tAverage Score: 14.73\tAverage Time: 1.03\tBest Score Saved: 15.38\n",
      "Episode 900\tAverage Score: 15.23\tAverage Time: 1.03\tBest Score Saved: 15.38\n",
      "Episode 1000\tAverage Score: 15.38\tAverage Time: 1.03\tBest Score Saved: 15.70\n",
      "\n",
      "\n",
      "Agent 002:\n",
      "\n",
      "Episode 100\tAverage Score: 0.18\tAverage Time: 1.00\tBest Score Saved: -100.00\n",
      "Episode 200\tAverage Score: 1.57\tAverage Time: 1.01\tBest Score Saved: -100.00\n",
      "Episode 300\tAverage Score: 6.17\tAverage Time: 1.02\tBest Score Saved: -100.00\n",
      "Episode 400\tAverage Score: 10.02\tAverage Time: 1.03\tBest Score Saved: -100.00\n",
      "Episode 500\tAverage Score: 13.43\tAverage Time: 1.03\tBest Score Saved: 13.50\n",
      "Episode 600\tAverage Score: 14.74\tAverage Time: 1.03\tBest Score Saved: 14.66\n",
      "Episode 700\tAverage Score: 15.59\tAverage Time: 1.03\tBest Score Saved: 15.77\n",
      "Episode 800\tAverage Score: 15.50\tAverage Time: 1.03\tBest Score Saved: 15.78\n",
      "Episode 900\tAverage Score: 16.32\tAverage Time: 1.03\tBest Score Saved: 16.51\n",
      "Episode 1000\tAverage Score: 15.54\tAverage Time: 1.03\tBest Score Saved: 16.52\n",
      "\n",
      "\n",
      "Agent 003:\n",
      "\n",
      "Episode 100\tAverage Score: 0.34\tAverage Time: 1.00\tBest Score Saved: -100.00\n",
      "Episode 200\tAverage Score: 2.79\tAverage Time: 1.01\tBest Score Saved: -100.00\n",
      "Episode 300\tAverage Score: 6.80\tAverage Time: 1.02\tBest Score Saved: -100.00\n",
      "Episode 400\tAverage Score: 11.31\tAverage Time: 1.03\tBest Score Saved: 11.3300\n",
      "Episode 500\tAverage Score: 13.30\tAverage Time: 1.04\tBest Score Saved: 13.21\n",
      "Episode 600\tAverage Score: 15.12\tAverage Time: 1.03\tBest Score Saved: 15.13\n",
      "Episode 700\tAverage Score: 15.55\tAverage Time: 1.03\tBest Score Saved: 16.01\n",
      "Episode 800\tAverage Score: 15.48\tAverage Time: 1.03\tBest Score Saved: 16.01\n",
      "Episode 900\tAverage Score: 15.21\tAverage Time: 1.03\tBest Score Saved: 16.01\n",
      "Episode 1000\tAverage Score: 15.11\tAverage Time: 1.03\tBest Score Saved: 16.01\n",
      "\n",
      "\n",
      "Agent 004:\n",
      "\n",
      "Episode 100\tAverage Score: 1.01\tAverage Time: 1.00\tBest Score Saved: -100.00\n",
      "Episode 200\tAverage Score: 4.33\tAverage Time: 1.01\tBest Score Saved: -100.00\n",
      "Episode 300\tAverage Score: 7.83\tAverage Time: 1.02\tBest Score Saved: -100.00\n",
      "Episode 400\tAverage Score: 9.82\tAverage Time: 1.03\tBest Score Saved: -100.00\n",
      "Episode 500\tAverage Score: 13.20\tAverage Time: 1.03\tBest Score Saved: 13.2000\n",
      "Episode 600\tAverage Score: 14.72\tAverage Time: 1.03\tBest Score Saved: 14.76\n",
      "Episode 700\tAverage Score: 14.90\tAverage Time: 1.04\tBest Score Saved: 15.10\n",
      "Episode 800\tAverage Score: 15.12\tAverage Time: 1.03\tBest Score Saved: 15.41\n",
      "Episode 900\tAverage Score: 14.58\tAverage Time: 1.03\tBest Score Saved: 15.41\n",
      "Episode 1000\tAverage Score: 14.37\tAverage Time: 1.03\tBest Score Saved: 15.41\n",
      "\n",
      "\n",
      "Agent 005:\n",
      "\n",
      "Episode 100\tAverage Score: 0.72\tAverage Time: 1.00\tBest Score Saved: -100.00\n",
      "Episode 200\tAverage Score: 3.73\tAverage Time: 1.01\tBest Score Saved: -100.00\n",
      "Episode 300\tAverage Score: 7.02\tAverage Time: 1.02\tBest Score Saved: -100.00\n",
      "Episode 400\tAverage Score: 11.11\tAverage Time: 1.03\tBest Score Saved: 11.2100\n",
      "Episode 500\tAverage Score: 14.11\tAverage Time: 1.03\tBest Score Saved: 13.94\n",
      "Episode 600\tAverage Score: 15.48\tAverage Time: 1.03\tBest Score Saved: 15.56\n",
      "Episode 700\tAverage Score: 15.89\tAverage Time: 1.03\tBest Score Saved: 16.17\n",
      "Episode 800\tAverage Score: 15.45\tAverage Time: 1.03\tBest Score Saved: 16.17\n",
      "Episode 900\tAverage Score: 16.35\tAverage Time: 1.03\tBest Score Saved: 16.39\n",
      "Episode 1000\tAverage Score: 15.93\tAverage Time: 1.03\tBest Score Saved: 16.39\n",
      "\n",
      "\n",
      "Agent 006:\n",
      "\n",
      "Episode 100\tAverage Score: 0.56\tAverage Time: 1.00\tBest Score Saved: -100.00\n",
      "Episode 200\tAverage Score: 3.49\tAverage Time: 1.01\tBest Score Saved: -100.00\n",
      "Episode 300\tAverage Score: 7.57\tAverage Time: 1.02\tBest Score Saved: -100.00\n",
      "Episode 400\tAverage Score: 10.17\tAverage Time: 1.03\tBest Score Saved: 10.2600\n",
      "Episode 500\tAverage Score: 13.20\tAverage Time: 1.03\tBest Score Saved: 13.12\n",
      "Episode 600\tAverage Score: 15.04\tAverage Time: 1.03\tBest Score Saved: 15.11\n",
      "Episode 700\tAverage Score: 15.21\tAverage Time: 1.03\tBest Score Saved: 15.30\n",
      "Episode 800\tAverage Score: 14.80\tAverage Time: 1.03\tBest Score Saved: 15.74\n",
      "Episode 900\tAverage Score: 15.55\tAverage Time: 1.03\tBest Score Saved: 15.74\n",
      "Episode 1000\tAverage Score: 15.51\tAverage Time: 1.03\tBest Score Saved: 16.08\n",
      "\n",
      "\n",
      "Agent 007:\n",
      "\n",
      "Episode 100\tAverage Score: 0.46\tAverage Time: 1.00\tBest Score Saved: -100.00\n",
      "Episode 200\tAverage Score: 2.35\tAverage Time: 1.01\tBest Score Saved: -100.00\n",
      "Episode 300\tAverage Score: 7.13\tAverage Time: 1.02\tBest Score Saved: -100.00\n",
      "Episode 400\tAverage Score: 10.14\tAverage Time: 1.03\tBest Score Saved: 10.0700\n",
      "Episode 500\tAverage Score: 13.12\tAverage Time: 1.03\tBest Score Saved: 13.27\n",
      "Episode 600\tAverage Score: 13.46\tAverage Time: 1.03\tBest Score Saved: 13.74\n",
      "Episode 700\tAverage Score: 13.70\tAverage Time: 1.03\tBest Score Saved: 14.09\n",
      "Episode 800\tAverage Score: 14.97\tAverage Time: 1.03\tBest Score Saved: 14.97\n",
      "Episode 900\tAverage Score: 15.18\tAverage Time: 1.03\tBest Score Saved: 15.31\n",
      "Episode 1000\tAverage Score: 15.59\tAverage Time: 1.03\tBest Score Saved: 15.77\n",
      "\n",
      "\n",
      "Agent 008:\n",
      "\n",
      "Episode 100\tAverage Score: 0.15\tAverage Time: 1.00\tBest Score Saved: -100.00\n",
      "Episode 200\tAverage Score: 3.48\tAverage Time: 1.01\tBest Score Saved: -100.00\n",
      "Episode 300\tAverage Score: 6.44\tAverage Time: 1.02\tBest Score Saved: -100.00\n",
      "Episode 400\tAverage Score: 10.72\tAverage Time: 1.03\tBest Score Saved: 10.7400\n",
      "Episode 500\tAverage Score: 12.15\tAverage Time: 1.03\tBest Score Saved: 12.14\n",
      "Episode 600\tAverage Score: 13.78\tAverage Time: 1.03\tBest Score Saved: 13.92\n",
      "Episode 700\tAverage Score: 14.17\tAverage Time: 1.03\tBest Score Saved: 14.46\n",
      "Episode 800\tAverage Score: 15.06\tAverage Time: 1.03\tBest Score Saved: 15.13\n",
      "Episode 900\tAverage Score: 15.57\tAverage Time: 1.03\tBest Score Saved: 15.78\n",
      "Episode 1000\tAverage Score: 15.44\tAverage Time: 1.03\tBest Score Saved: 15.90\n",
      "\n",
      "\n",
      "Agent 009:\n",
      "\n",
      "Episode 100\tAverage Score: 0.04\tAverage Time: 1.01\tBest Score Saved: -100.00\n",
      "Episode 200\tAverage Score: 2.84\tAverage Time: 1.01\tBest Score Saved: -100.00\n",
      "Episode 300\tAverage Score: 6.83\tAverage Time: 1.02\tBest Score Saved: -100.00\n",
      "Episode 400\tAverage Score: 10.26\tAverage Time: 1.03\tBest Score Saved: 10.2800\n",
      "Episode 500\tAverage Score: 12.81\tAverage Time: 1.03\tBest Score Saved: 12.78\n",
      "Episode 600\tAverage Score: 15.23\tAverage Time: 1.03\tBest Score Saved: 15.31\n",
      "Episode 700\tAverage Score: 15.05\tAverage Time: 1.03\tBest Score Saved: 15.33\n",
      "Episode 800\tAverage Score: 15.20\tAverage Time: 1.03\tBest Score Saved: 15.37\n",
      "Episode 900\tAverage Score: 15.31\tAverage Time: 1.03\tBest Score Saved: 15.67\n",
      "Episode 1000\tAverage Score: 15.80\tAverage Time: 1.04\tBest Score Saved: 16.23\n"
     ]
    }
   ],
   "source": [
    "# Double DQN\n",
    "ddqn_scores = []\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"\\n\\nAgent {:03d}:\\n\".format(i))\n",
    "    agent = Agent(state_size=state_size, action_size=action_size, seed=i*100, ddqn=True, sampling_mode=\"Uniform\", dueling=False )\n",
    "    scores = dqn(agent, filename = \"ddqn{:03d}.pth\".format(i))\n",
    "    ddqn_scores.append(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model 3: DQN (no double DQN or dueling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Agent 000:\n",
      "\n",
      "\n",
      "Episode 100\tAverage Score: 0.80\tAverage Time: 0.98\tBest Score Saved: -100.00\n",
      "Episode 200\tAverage Score: 3.86\tAverage Time: 0.99\tBest Score Saved: -100.00\n",
      "Episode 300\tAverage Score: 6.92\tAverage Time: 1.00\tBest Score Saved: -100.00\n",
      "Episode 400\tAverage Score: 10.42\tAverage Time: 1.01\tBest Score Saved: 10.4800\n",
      "Episode 500\tAverage Score: 12.86\tAverage Time: 1.01\tBest Score Saved: 12.74\n",
      "Episode 600\tAverage Score: 15.36\tAverage Time: 1.01\tBest Score Saved: 15.35\n",
      "Episode 700\tAverage Score: 14.43\tAverage Time: 1.01\tBest Score Saved: 15.41\n",
      "Episode 800\tAverage Score: 15.39\tAverage Time: 1.01\tBest Score Saved: 15.69\n",
      "Episode 900\tAverage Score: 15.89\tAverage Time: 1.01\tBest Score Saved: 16.01\n",
      "Episode 1000\tAverage Score: 14.62\tAverage Time: 1.01\tBest Score Saved: 16.05\n",
      "\n",
      "\n",
      "Agent 001:\n",
      "\n",
      "\n",
      "Episode 100\tAverage Score: 0.72\tAverage Time: 0.98\tBest Score Saved: -100.00\n",
      "Episode 200\tAverage Score: 3.98\tAverage Time: 0.99\tBest Score Saved: -100.00\n",
      "Episode 300\tAverage Score: 6.91\tAverage Time: 1.00\tBest Score Saved: -100.00\n",
      "Episode 400\tAverage Score: 10.61\tAverage Time: 1.01\tBest Score Saved: 10.5200\n",
      "Episode 500\tAverage Score: 12.86\tAverage Time: 1.01\tBest Score Saved: 12.96\n",
      "Episode 600\tAverage Score: 14.36\tAverage Time: 1.01\tBest Score Saved: 14.38\n",
      "Episode 700\tAverage Score: 14.13\tAverage Time: 1.01\tBest Score Saved: 15.03\n",
      "Episode 800\tAverage Score: 14.99\tAverage Time: 1.01\tBest Score Saved: 15.07\n",
      "Episode 900\tAverage Score: 14.31\tAverage Time: 1.01\tBest Score Saved: 15.27\n",
      "Episode 1000\tAverage Score: 15.23\tAverage Time: 1.02\tBest Score Saved: 15.31\n",
      "\n",
      "\n",
      "Agent 002:\n",
      "\n",
      "\n",
      "Episode 100\tAverage Score: 0.39\tAverage Time: 0.99\tBest Score Saved: -100.00\n",
      "Episode 200\tAverage Score: 3.49\tAverage Time: 1.00\tBest Score Saved: -100.00\n",
      "Episode 300\tAverage Score: 7.44\tAverage Time: 1.00\tBest Score Saved: -100.00\n",
      "Episode 400\tAverage Score: 9.96\tAverage Time: 1.01\tBest Score Saved: 10.01.00\n",
      "Episode 500\tAverage Score: 13.24\tAverage Time: 1.01\tBest Score Saved: 13.12\n",
      "Episode 600\tAverage Score: 14.62\tAverage Time: 1.01\tBest Score Saved: 14.60\n",
      "Episode 700\tAverage Score: 14.99\tAverage Time: 1.01\tBest Score Saved: 15.18\n",
      "Episode 800\tAverage Score: 15.65\tAverage Time: 1.01\tBest Score Saved: 16.01\n",
      "Episode 900\tAverage Score: 15.73\tAverage Time: 1.01\tBest Score Saved: 16.01\n",
      "Episode 1000\tAverage Score: 14.72\tAverage Time: 1.01\tBest Score Saved: 16.01\n",
      "\n",
      "\n",
      "Agent 003:\n",
      "\n",
      "\n",
      "Episode 100\tAverage Score: 0.44\tAverage Time: 0.98\tBest Score Saved: -100.00\n",
      "Episode 200\tAverage Score: 2.91\tAverage Time: 0.99\tBest Score Saved: -100.00\n",
      "Episode 300\tAverage Score: 5.77\tAverage Time: 1.00\tBest Score Saved: -100.00\n",
      "Episode 400\tAverage Score: 10.05\tAverage Time: 1.01\tBest Score Saved: 10.0500\n",
      "Episode 500\tAverage Score: 12.62\tAverage Time: 1.01\tBest Score Saved: 12.61\n",
      "Episode 600\tAverage Score: 14.21\tAverage Time: 1.01\tBest Score Saved: 14.20\n",
      "Episode 700\tAverage Score: 14.18\tAverage Time: 1.01\tBest Score Saved: 14.55\n",
      "Episode 800\tAverage Score: 14.93\tAverage Time: 1.01\tBest Score Saved: 15.00\n",
      "Episode 900\tAverage Score: 14.26\tAverage Time: 1.01\tBest Score Saved: 15.13\n",
      "Episode 1000\tAverage Score: 15.26\tAverage Time: 1.01\tBest Score Saved: 15.21\n",
      "\n",
      "\n",
      "Agent 004:\n",
      "\n",
      "\n",
      "Episode 100\tAverage Score: 0.49\tAverage Time: 0.98\tBest Score Saved: -100.00\n",
      "Episode 200\tAverage Score: 3.21\tAverage Time: 0.99\tBest Score Saved: -100.00\n",
      "Episode 300\tAverage Score: 6.34\tAverage Time: 1.00\tBest Score Saved: -100.00\n",
      "Episode 400\tAverage Score: 9.43\tAverage Time: 1.01\tBest Score Saved: -100.00\n",
      "Episode 500\tAverage Score: 12.22\tAverage Time: 1.01\tBest Score Saved: 12.2400\n",
      "Episode 600\tAverage Score: 14.17\tAverage Time: 1.01\tBest Score Saved: 14.19\n",
      "Episode 700\tAverage Score: 14.17\tAverage Time: 1.01\tBest Score Saved: 14.72\n",
      "Episode 800\tAverage Score: 14.12\tAverage Time: 1.01\tBest Score Saved: 14.72\n",
      "Episode 900\tAverage Score: 14.41\tAverage Time: 1.01\tBest Score Saved: 14.85\n",
      "Episode 1000\tAverage Score: 15.30\tAverage Time: 1.01\tBest Score Saved: 15.70\n",
      "\n",
      "\n",
      "Agent 005:\n",
      "\n",
      "\n",
      "Episode 100\tAverage Score: 0.15\tAverage Time: 0.98\tBest Score Saved: -100.00\n",
      "Episode 200\tAverage Score: 2.54\tAverage Time: 0.99\tBest Score Saved: -100.00\n",
      "Episode 300\tAverage Score: 7.04\tAverage Time: 1.00\tBest Score Saved: -100.00\n",
      "Episode 400\tAverage Score: 9.45\tAverage Time: 1.01\tBest Score Saved: -100.00\n",
      "Episode 500\tAverage Score: 12.81\tAverage Time: 1.01\tBest Score Saved: 12.9000\n",
      "Episode 600\tAverage Score: 14.98\tAverage Time: 1.01\tBest Score Saved: 14.88\n",
      "Episode 700\tAverage Score: 15.11\tAverage Time: 1.01\tBest Score Saved: 15.31\n",
      "Episode 800\tAverage Score: 14.96\tAverage Time: 1.01\tBest Score Saved: 15.32\n",
      "Episode 900\tAverage Score: 14.81\tAverage Time: 1.01\tBest Score Saved: 15.32\n",
      "Episode 1000\tAverage Score: 14.83\tAverage Time: 1.01\tBest Score Saved: 15.32\n",
      "\n",
      "\n",
      "Agent 006:\n",
      "\n",
      "\n",
      "Episode 100\tAverage Score: 1.04\tAverage Time: 0.98\tBest Score Saved: -100.00\n",
      "Episode 200\tAverage Score: 3.77\tAverage Time: 0.99\tBest Score Saved: -100.00\n",
      "Episode 300\tAverage Score: 7.00\tAverage Time: 1.01\tBest Score Saved: -100.00\n",
      "Episode 400\tAverage Score: 11.53\tAverage Time: 1.02\tBest Score Saved: 11.5600\n",
      "Episode 500\tAverage Score: 13.66\tAverage Time: 1.01\tBest Score Saved: 13.72\n",
      "Episode 600\tAverage Score: 13.96\tAverage Time: 1.01\tBest Score Saved: 14.27\n",
      "Episode 700\tAverage Score: 15.14\tAverage Time: 1.01\tBest Score Saved: 15.18\n",
      "Episode 800\tAverage Score: 15.17\tAverage Time: 1.01\tBest Score Saved: 15.72\n",
      "Episode 900\tAverage Score: 15.66\tAverage Time: 1.01\tBest Score Saved: 15.75\n",
      "Episode 1000\tAverage Score: 15.85\tAverage Time: 1.01\tBest Score Saved: 16.11\n",
      "\n",
      "\n",
      "Agent 007:\n",
      "\n",
      "\n",
      "Episode 100\tAverage Score: 0.48\tAverage Time: 0.98\tBest Score Saved: -100.00\n",
      "Episode 200\tAverage Score: 2.75\tAverage Time: 0.99\tBest Score Saved: -100.00\n",
      "Episode 300\tAverage Score: 7.07\tAverage Time: 1.00\tBest Score Saved: -100.00\n",
      "Episode 400\tAverage Score: 10.77\tAverage Time: 1.01\tBest Score Saved: 10.7200\n",
      "Episode 500\tAverage Score: 12.69\tAverage Time: 1.01\tBest Score Saved: 12.61\n",
      "Episode 600\tAverage Score: 14.28\tAverage Time: 1.01\tBest Score Saved: 14.64\n",
      "Episode 700\tAverage Score: 14.43\tAverage Time: 1.01\tBest Score Saved: 14.64\n",
      "Episode 800\tAverage Score: 14.69\tAverage Time: 1.01\tBest Score Saved: 14.79\n",
      "Episode 900\tAverage Score: 14.57\tAverage Time: 1.01\tBest Score Saved: 14.91\n",
      "Episode 1000\tAverage Score: 15.34\tAverage Time: 1.01\tBest Score Saved: 15.40\n",
      "\n",
      "\n",
      "Agent 008:\n",
      "\n",
      "\n",
      "Episode 100\tAverage Score: 0.37\tAverage Time: 0.98\tBest Score Saved: -100.00\n",
      "Episode 200\tAverage Score: 3.17\tAverage Time: 0.99\tBest Score Saved: -100.00\n",
      "Episode 300\tAverage Score: 6.62\tAverage Time: 1.00\tBest Score Saved: -100.00\n",
      "Episode 400\tAverage Score: 10.63\tAverage Time: 1.01\tBest Score Saved: 10.5600\n",
      "Episode 500\tAverage Score: 12.62\tAverage Time: 1.01\tBest Score Saved: 12.60\n",
      "Episode 600\tAverage Score: 13.85\tAverage Time: 1.01\tBest Score Saved: 13.88\n",
      "Episode 700\tAverage Score: 13.78\tAverage Time: 1.01\tBest Score Saved: 13.88\n",
      "Episode 800\tAverage Score: 14.89\tAverage Time: 1.01\tBest Score Saved: 14.88\n",
      "Episode 900\tAverage Score: 15.83\tAverage Time: 1.01\tBest Score Saved: 15.99\n",
      "Episode 1000\tAverage Score: 15.45\tAverage Time: 1.01\tBest Score Saved: 16.16\n",
      "\n",
      "\n",
      "Agent 009:\n",
      "\n",
      "\n",
      "Episode 100\tAverage Score: 0.81\tAverage Time: 0.98\tBest Score Saved: -100.00\n",
      "Episode 200\tAverage Score: 4.35\tAverage Time: 0.99\tBest Score Saved: -100.00\n",
      "Episode 300\tAverage Score: 6.86\tAverage Time: 1.00\tBest Score Saved: -100.00\n",
      "Episode 400\tAverage Score: 10.35\tAverage Time: 1.01\tBest Score Saved: 10.2400\n",
      "Episode 500\tAverage Score: 13.21\tAverage Time: 1.01\tBest Score Saved: 13.36\n",
      "Episode 600\tAverage Score: 13.76\tAverage Time: 1.01\tBest Score Saved: 13.93\n",
      "Episode 700\tAverage Score: 15.09\tAverage Time: 1.01\tBest Score Saved: 15.05\n",
      "Episode 800\tAverage Score: 15.65\tAverage Time: 1.01\tBest Score Saved: 15.80\n",
      "Episode 900\tAverage Score: 15.78\tAverage Time: 1.02\tBest Score Saved: 16.07\n",
      "Episode 1000\tAverage Score: 15.02\tAverage Time: 1.03\tBest Score Saved: 16.07\n"
     ]
    }
   ],
   "source": [
    "# DQN\n",
    "dqn_scores = []\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"\\n\\nAgent {:03d}:\\n\\n\".format(i))\n",
    "    agent = Agent(state_size=state_size, action_size=action_size, seed=i*100, ddqn=False, sampling_mode=\"Uniform\", dueling=False )\n",
    "    scores = dqn(agent, filename = \"dqn{:03d}.pth\".format(i))\n",
    "    dqn_scores.append(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model 4: DQN with Dueling (no Double DQN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Agent 000:\n",
      "\n",
      "\n",
      "Episode 100\tAverage Score: 0.97\tAverage Time: 1.09\tBest Score Saved: -100.00\n",
      "Episode 200\tAverage Score: 4.28\tAverage Time: 1.09\tBest Score Saved: -100.00\n",
      "Episode 300\tAverage Score: 7.40\tAverage Time: 1.12\tBest Score Saved: -100.00\n",
      "Episode 400\tAverage Score: 11.44\tAverage Time: 1.12\tBest Score Saved: 11.2800\n",
      "Episode 500\tAverage Score: 13.93\tAverage Time: 1.11\tBest Score Saved: 14.19\n",
      "Episode 600\tAverage Score: 15.57\tAverage Time: 1.11\tBest Score Saved: 15.53\n",
      "Episode 700\tAverage Score: 14.84\tAverage Time: 1.11\tBest Score Saved: 15.71\n",
      "Episode 800\tAverage Score: 13.83\tAverage Time: 1.11\tBest Score Saved: 15.71\n",
      "Episode 900\tAverage Score: 13.81\tAverage Time: 1.12\tBest Score Saved: 15.71\n",
      "Episode 1000\tAverage Score: 14.64\tAverage Time: 1.12\tBest Score Saved: 15.71\n",
      "\n",
      "\n",
      "Agent 001:\n",
      "\n",
      "\n",
      "Episode 100\tAverage Score: 0.23\tAverage Time: 1.10\tBest Score Saved: -100.00\n",
      "Episode 200\tAverage Score: 3.08\tAverage Time: 1.11\tBest Score Saved: -100.00\n",
      "Episode 300\tAverage Score: 6.02\tAverage Time: 1.11\tBest Score Saved: -100.00\n",
      "Episode 400\tAverage Score: 9.51\tAverage Time: 1.12\tBest Score Saved: -100.00\n",
      "Episode 500\tAverage Score: 12.38\tAverage Time: 1.12\tBest Score Saved: 12.4700\n",
      "Episode 600\tAverage Score: 14.25\tAverage Time: 1.12\tBest Score Saved: 14.29\n",
      "Episode 700\tAverage Score: 15.39\tAverage Time: 1.12\tBest Score Saved: 15.58\n",
      "Episode 800\tAverage Score: 15.34\tAverage Time: 1.12\tBest Score Saved: 15.58\n",
      "Episode 900\tAverage Score: 15.13\tAverage Time: 1.12\tBest Score Saved: 15.58\n",
      "Episode 1000\tAverage Score: 15.71\tAverage Time: 1.12\tBest Score Saved: 15.89\n",
      "\n",
      "\n",
      "Agent 002:\n",
      "\n",
      "\n",
      "Episode 100\tAverage Score: 0.86\tAverage Time: 1.10\tBest Score Saved: -100.00\n",
      "Episode 200\tAverage Score: 4.17\tAverage Time: 1.11\tBest Score Saved: -100.00\n",
      "Episode 300\tAverage Score: 6.89\tAverage Time: 1.10\tBest Score Saved: -100.00\n",
      "Episode 400\tAverage Score: 10.41\tAverage Time: 1.10\tBest Score Saved: 10.3800\n",
      "Episode 500\tAverage Score: 13.09\tAverage Time: 1.13\tBest Score Saved: 13.21\n",
      "Episode 600\tAverage Score: 14.05\tAverage Time: 1.12\tBest Score Saved: 14.29\n",
      "Episode 700\tAverage Score: 14.34\tAverage Time: 1.12\tBest Score Saved: 14.31\n",
      "Episode 800\tAverage Score: 13.84\tAverage Time: 1.12\tBest Score Saved: 14.65\n",
      "Episode 900\tAverage Score: 15.10\tAverage Time: 1.12\tBest Score Saved: 15.10\n",
      "Episode 1000\tAverage Score: 15.21\tAverage Time: 1.12\tBest Score Saved: 15.38\n",
      "\n",
      "\n",
      "Agent 003:\n",
      "\n",
      "\n",
      "Episode 100\tAverage Score: 0.81\tAverage Time: 1.10\tBest Score Saved: -100.00\n",
      "Episode 200\tAverage Score: 4.56\tAverage Time: 1.10\tBest Score Saved: -100.00\n",
      "Episode 300\tAverage Score: 7.71\tAverage Time: 1.12\tBest Score Saved: -100.00\n",
      "Episode 400\tAverage Score: 9.75\tAverage Time: 1.12\tBest Score Saved: -100.00\n",
      "Episode 500\tAverage Score: 12.85\tAverage Time: 1.13\tBest Score Saved: 12.8300\n",
      "Episode 600\tAverage Score: 14.52\tAverage Time: 1.12\tBest Score Saved: 14.62\n",
      "Episode 700\tAverage Score: 15.10\tAverage Time: 1.12\tBest Score Saved: 15.11\n",
      "Episode 800\tAverage Score: 15.88\tAverage Time: 1.12\tBest Score Saved: 16.53\n",
      "Episode 900\tAverage Score: 14.56\tAverage Time: 1.10\tBest Score Saved: 16.53\n",
      "Episode 1000\tAverage Score: 13.92\tAverage Time: 1.10\tBest Score Saved: 16.53\n",
      "\n",
      "\n",
      "Agent 004:\n",
      "\n",
      "\n",
      "Episode 100\tAverage Score: 0.92\tAverage Time: 1.08\tBest Score Saved: -100.00\n",
      "Episode 200\tAverage Score: 3.88\tAverage Time: 1.09\tBest Score Saved: -100.00\n",
      "Episode 300\tAverage Score: 6.43\tAverage Time: 1.10\tBest Score Saved: -100.00\n",
      "Episode 400\tAverage Score: 10.64\tAverage Time: 1.10\tBest Score Saved: 10.6800\n",
      "Episode 500\tAverage Score: 13.39\tAverage Time: 1.10\tBest Score Saved: 13.36\n",
      "Episode 600\tAverage Score: 14.54\tAverage Time: 1.10\tBest Score Saved: 14.56\n",
      "Episode 700\tAverage Score: 15.47\tAverage Time: 1.10\tBest Score Saved: 15.85\n",
      "Episode 800\tAverage Score: 15.70\tAverage Time: 1.10\tBest Score Saved: 16.24\n",
      "Episode 900\tAverage Score: 15.67\tAverage Time: 1.10\tBest Score Saved: 16.24\n",
      "Episode 1000\tAverage Score: 15.77\tAverage Time: 1.10\tBest Score Saved: 16.24\n",
      "\n",
      "\n",
      "Agent 005:\n",
      "\n",
      "\n",
      "Episode 100\tAverage Score: 0.66\tAverage Time: 1.08\tBest Score Saved: -100.00\n",
      "Episode 200\tAverage Score: 3.90\tAverage Time: 1.09\tBest Score Saved: -100.00\n",
      "Episode 300\tAverage Score: 7.57\tAverage Time: 1.09\tBest Score Saved: -100.00\n",
      "Episode 400\tAverage Score: 10.06\tAverage Time: 1.10\tBest Score Saved: 10.0600\n",
      "Episode 500\tAverage Score: 12.46\tAverage Time: 1.10\tBest Score Saved: 12.56\n",
      "Episode 600\tAverage Score: 14.60\tAverage Time: 1.10\tBest Score Saved: 14.61\n",
      "Episode 700\tAverage Score: 14.47\tAverage Time: 1.10\tBest Score Saved: 14.98\n",
      "Episode 800\tAverage Score: 15.31\tAverage Time: 1.10\tBest Score Saved: 15.60\n",
      "Episode 900\tAverage Score: 15.67\tAverage Time: 1.10\tBest Score Saved: 15.67\n",
      "Episode 1000\tAverage Score: 15.01\tAverage Time: 1.10\tBest Score Saved: 16.13\n",
      "\n",
      "\n",
      "Agent 006:\n",
      "\n",
      "\n",
      "Episode 100\tAverage Score: 1.00\tAverage Time: 1.08\tBest Score Saved: -100.00\n",
      "Episode 200\tAverage Score: 4.48\tAverage Time: 1.10\tBest Score Saved: -100.00\n",
      "Episode 300\tAverage Score: 7.59\tAverage Time: 1.10\tBest Score Saved: -100.00\n",
      "Episode 400\tAverage Score: 10.22\tAverage Time: 1.10\tBest Score Saved: 10.2100\n",
      "Episode 500\tAverage Score: 13.65\tAverage Time: 1.10\tBest Score Saved: 13.71\n",
      "Episode 600\tAverage Score: 14.93\tAverage Time: 1.10\tBest Score Saved: 15.01\n",
      "Episode 700\tAverage Score: 15.78\tAverage Time: 1.10\tBest Score Saved: 15.85\n",
      "Episode 800\tAverage Score: 15.77\tAverage Time: 1.11\tBest Score Saved: 16.29\n",
      "Episode 900\tAverage Score: 14.93\tAverage Time: 1.10\tBest Score Saved: 16.29\n",
      "Episode 1000\tAverage Score: 14.18\tAverage Time: 1.10\tBest Score Saved: 16.29\n",
      "\n",
      "\n",
      "Agent 007:\n",
      "\n",
      "\n",
      "Episode 100\tAverage Score: 0.03\tAverage Time: 1.08\tBest Score Saved: -100.00\n",
      "Episode 200\tAverage Score: 2.65\tAverage Time: 1.09\tBest Score Saved: -100.00\n",
      "Episode 300\tAverage Score: 6.74\tAverage Time: 1.10\tBest Score Saved: -100.00\n",
      "Episode 400\tAverage Score: 9.11\tAverage Time: 1.10\tBest Score Saved: -100.00\n",
      "Episode 500\tAverage Score: 12.92\tAverage Time: 1.10\tBest Score Saved: 12.8500\n",
      "Episode 600\tAverage Score: 13.98\tAverage Time: 1.10\tBest Score Saved: 14.35\n",
      "Episode 700\tAverage Score: 14.73\tAverage Time: 1.10\tBest Score Saved: 14.82\n",
      "Episode 800\tAverage Score: 14.48\tAverage Time: 1.10\tBest Score Saved: 14.82\n",
      "Episode 900\tAverage Score: 14.57\tAverage Time: 1.10\tBest Score Saved: 15.01\n",
      "Episode 1000\tAverage Score: 14.56\tAverage Time: 1.10\tBest Score Saved: 15.01\n",
      "\n",
      "\n",
      "Agent 008:\n",
      "\n",
      "\n",
      "Episode 100\tAverage Score: 0.56\tAverage Time: 1.08\tBest Score Saved: -100.00\n",
      "Episode 200\tAverage Score: 3.47\tAverage Time: 1.09\tBest Score Saved: -100.00\n",
      "Episode 300\tAverage Score: 7.18\tAverage Time: 1.10\tBest Score Saved: -100.00\n",
      "Episode 400\tAverage Score: 10.89\tAverage Time: 1.10\tBest Score Saved: 10.8300\n",
      "Episode 500\tAverage Score: 14.06\tAverage Time: 1.10\tBest Score Saved: 14.12\n",
      "Episode 600\tAverage Score: 15.72\tAverage Time: 1.10\tBest Score Saved: 15.64\n",
      "Episode 700\tAverage Score: 15.72\tAverage Time: 1.11\tBest Score Saved: 16.08\n",
      "Episode 800\tAverage Score: 14.78\tAverage Time: 1.10\tBest Score Saved: 16.08\n",
      "Episode 900\tAverage Score: 15.78\tAverage Time: 1.10\tBest Score Saved: 16.08\n",
      "Episode 1000\tAverage Score: 14.37\tAverage Time: 1.10\tBest Score Saved: 16.08\n",
      "\n",
      "\n",
      "Agent 009:\n",
      "\n",
      "\n",
      "Episode 100\tAverage Score: 0.80\tAverage Time: 1.08\tBest Score Saved: -100.00\n",
      "Episode 200\tAverage Score: 3.58\tAverage Time: 1.09\tBest Score Saved: -100.00\n",
      "Episode 300\tAverage Score: 6.42\tAverage Time: 1.10\tBest Score Saved: -100.00\n",
      "Episode 400\tAverage Score: 10.63\tAverage Time: 1.10\tBest Score Saved: 10.5300\n",
      "Episode 500\tAverage Score: 13.57\tAverage Time: 1.10\tBest Score Saved: 13.56\n",
      "Episode 600\tAverage Score: 15.32\tAverage Time: 1.10\tBest Score Saved: 15.36\n",
      "Episode 700\tAverage Score: 14.80\tAverage Time: 1.10\tBest Score Saved: 15.59\n",
      "Episode 800\tAverage Score: 15.04\tAverage Time: 1.10\tBest Score Saved: 15.59\n",
      "Episode 900\tAverage Score: 15.69\tAverage Time: 1.13\tBest Score Saved: 15.76\n",
      "Episode 1000\tAverage Score: 16.03\tAverage Time: 1.11\tBest Score Saved: 16.06\n"
     ]
    }
   ],
   "source": [
    "# Dueling\n",
    "dueling_scores = []\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"\\n\\nAgent {:03d}:\\n\\n\".format(i))\n",
    "    agent = Agent(state_size=state_size, action_size=action_size, seed=i*100, ddqn=False, sampling_mode=\"Uniform\", dueling=True )\n",
    "    scores = dqn(agent, filename = \"dueling{:03d}.pth\".format(i))\n",
    "    dueling_scores.append(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation of different training approaches\n",
    "\n",
    "We plot out the training scores across different training approaches below (averaged over 10 trainings with different initial seed). We do not notice any significant differenes across methodogies, and they can all solve the problem (score = 13) at around 500 episodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scores(scores, label, rolling_window=100):\n",
    "    scores = np.array(scores).mean(0)\n",
    "    rolling_mean = pd.Series(scores).rolling(rolling_window).mean()\n",
    "    plt.plot(rolling_mean, label = label);\n",
    "    plt.legend()\n",
    "    plt.xlabel('#episodes')\n",
    "    plt.ylabel('Avg score')\n",
    "    #plt.title(label);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEGCAYAAABiq/5QAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAABG/0lEQVR4nO3dd3hT1RvA8e9J0r0Xq1Ba9ijKkiFQGYKKKIooblzgQFBxoiIOEEQElSGgAiKCylAUQVHZSyxQKXtTSlu66W7T5Pz+SOQHWKBA23S8n+fJ0+Tm5t43p+2bk3PvfY/SWiOEEKLqMDg6ACGEEGVLEr8QQlQxkviFEKKKkcQvhBBVjCR+IYSoYkyODqA4AgMDdWhoqKPDEEKICmXbtm3JWuug85dXiMQfGhpKZGSko8MQQogKRSl1vKjlpTbUo5SapZRKVErtOm/5UKXUfqXUbqXU+NLavxBCiKKV5hj/HODmsxcopboBfYFrtNbNgQmluH8hhBBFKLXEr7VeB6Set/hpYJzWOt++TmJp7V8IIUTRyvqsnkZAF6XUX0qptUqp68p4/0IIUeWV9cFdE+AHdACuA75XStXTRRQMUkoNBgYDhISElGmQQghRmZV1jz8WWKJttgJWILCoFbXWM7XWbbXWbYOC/nM2khBCiCtU1on/R6A7gFKqEeAMJJdxDEIIUaWV5umcC4DNQGOlVKxS6nFgFlDPfornt8DAooZ5hBCiKsszW5i98Sh/7j2FxVryKbLUxvi11vdd4KkHS2ufQghR4WhN4aFV5Po35WiuOxsPpTB97WFO55oBmHJ/K/pcU6tEd1khrtwVQojKQmvNX0dTycwrpGXKcnyiZuCcshcv4DvzYyyxdCYXV57uWp8mNbzo2ax6iccgiV8IIQBOn4Qt0+D0CUg7Dr4hkHIY8k5Du0EQUB9O/AXOXhB+l+01gQ1sP7OS4FQ07FkKmQkQ1ASqNcUavYjYxFSOmurh4e1HsvLnVMxBAgpi6W3YikFpUrQXq60R9DeuY4zTLEb6/4lT2PUY698Fp3aDfgowluhbVRVhiL1t27ZaavUIIUpFTiqsGQdbZ/x/mdEFLPm25O/sCYl7LvjyJOfa+BfEY8RS5PMF2oiz+u9zZqM7p70a8nmdcdzYpgnX1XSC/Stg/UeQtB+w5+Z75kKzvlf01pRS27TWbc9fLj1+IcSVyzwFR9ZAYR4U5mHNTMV8dD/OxmQsftdgql4TfOpA496QnwnHN0DqEQi7AYJbX3i72cmwfiIc+NW2XnAbCGgAfmG2XnbmKdg607a8Se/ixao1HF4FBiPUbAlJ+2D5y5Cw8//rPPSjLV7/MCzpx8h2qYmnmxtf/baJo9GbqeXngVUZaZT5F3Fp2TTjMOTBAZqywRJOpLURO3QDQt230Nx1BzFpN3LTzX0ICT7AkaQT9DQFUqtxBFaTMwXaQlpBOq/6NsCg7OfZXHOP7ZaVCP8sgGrNoGHPK/zlXJj0+IUQVyYnlYIJN5Dy12nyM0yYXK1knnA7ZxVltFLt2gy0xUh2ohMArr5mvGrnUeDaFE+naIxuTtDyAeg0zJbw/nwXjm+84G7TDQYm+/kQZzLRJSeXfk7VcL32Pva36EtMZgxd8UC7B7AxN47O/uE4rR5NqmsIxrht+Bz95b8bdPOH5newtd4QolON7E/I4HD6YQ4ax2PVFiz5NVDGHAxO6aCNKO2GVVvwKGxNt+CeKLcjZKkjeBqqczovh7SCRHanbz6zeZMyUagLL/h+anjUwM/FDzeTG290eIPT+acxW8zkWfJwNjrTqVYnlFKX97v5t/0v0OOXxC9EJaUtFqy5uRg9PYtewVII+5dj3bYAbfLE2KAD5KZC41vBsxrWv74ibVsaGVv24VzDn+oPdsfQ6g5SZnxGxuL5FJ7Owppv25Qp0J/CZFtpLp+bIkAZKNi/m9xjybaeNqCcDBi9PClMzTgTgjJZ8e2SjmuNfPa5ONOowIy/sxe0fwrqdUN7VmN/dhxH4/9md/JuopKiiLHk45OmOB6o0UoRZIUWuTms8nAHwNVqJc9g60G3yjfzQHo6p41GqhVaWGcIZYubK/Wt2XhqV7a41aDA6kdWXhBZp2sRlhFLgfbC1+8n6qZn4pFroMDkRVS4kQIvyLPkkm/Jx9XoSp4l74Jtf0voLXQP6c6muE14OXtR3b061TyqcSLjBIfSD+FidCHMJwyNZtPJTRxKP0RKXkqR2/ow4kNuDru5yOcuRRK/EJWZxYw5IZGcyEh0YSGW9NOkfzefgpiTOAV64BZajYK4BJy8DFhyCtD5BVjzC7EUGLCYDWgrGE22XGApMOBePZ+cUy7/377SKIPG5GLFnGMbIfZp7g7VmhPw4lu4NLAd5LTm5WFwdT3zMq01+QcOYI6LwzMiAiwWklf/zvw931Cwcxe9tppxtkCcH+S4wqamBlo89ixWqwGnvcdYn7iZxLxkWh6x0uqwxmgFzwIjfhkWVEhd9jX0ZaflCO7ZWYTHW/AKKOC4wZ0sTwOH6lj5vbai0Kj+DQavXHDWTmQbLeS5WKmZCsEpmqYnNA3jNE1ii25e5e6Oc2govg8+AL26YNp/jGPHojhVwxWvPGjQogsnLCkooxFnozPNAppd9q/wt2O/sSNxB3W967IreRe31ruVxJxE+tTrg8lwZaPykviFqMAKYk9CoRnl5kbujijMcXE4u2Zi3DOP1F1WMvdl/+c1Jg8LJmcLeWnOYNA4e1iwFCgMzgZwN2I+ZUUbjbh2746lII/knCzSUgsIPbIHZc8LBb2aEdwgg8PxvriuO4xzSi7WQGfW9n2Qtd6diU3LJaJREP1aB5NwOo/1B5Oo5euGQSlqeLtS09cVNycjAZ4u7IxNZ9WJlaxNnYoVMy0C2hGIF+3/OELt3fEEnbB9E0jyhqCM/7wdjnlVJ94jABeLmSQ3P3qciMSkrbY4TU44F5r/85qU2nXwOxWHwWzB4mTEaC76ACxAQQ1/CvrcQP6aDXj4BdHkxZE4BQeTs207qbNnk/vPPxf9HZmCgvB74H68evTAkp6Oc2io7YNv/35cmzZFubqRs3UrltQU3K69FlNQEOa4OMzx8eRGR+PWogVGf3+cQ0IwBQSQuXo1udt3EPTcMJRJEr8QVUrKrNkkjr/InEVGcA4sxMnbQkCdTIzOVnI8apLV4Dpq3vIy/0RHM3OXlajsAPKy0snAA4DamYmccvfHbLQlFaXA1WQk12zBLy+D0y6eWO0HHT1dTBi0lfqx+zgUFEqeyYVqXq4EerkQHZvORS8uVQU4B6zH6HYMk+dBrPlB5Mb3x5pb98wqJoPiwQ516ZmxD7VoGh4p2WRaXfjTvzknvKqR4O5P73t6UivIm5Ppufyw4yQh5HJzsAsNXQu5tndXrOnp5B85iikokOxNm8lYsQJrxmnMJ+Ow5uTgHBqKS8MGYDBizc3B4OKKc/16GNzccW3WFI/rr0cZL3zapCUrm6SPPyY3Kgr3Nm3w7N6drNWrSZ0z59K/RPX/bx2XK3jiR3j3LuYB7P/sVhK/EOVS7s6d5B86jDUvl9SvvqIwMQmjpyfW/HycQ0PJ27kTJ18nCjPMuNVQ+IWlkNC0HXsjFUdO+7H+hnvZnm4tctvuzkZyCixU83KhVYgvXq5OHEnKokfT6tzaoia/7U5g7YEk6gZ48EzX+tTxdyfyWCrzt8YQ4OFMRKMgjAbFdaH+OBkNaK0xWzRO9uETpRQxKTkcS8nG1clIeLA3u05mEJO1l81Jv7L11CbSC2zTbjgb3Olc7TbeiRjO3rhcjqdkk2e24O5iYv3BZH7+J+5M3M4mAwWFVm4Jr0FIgDuNq3vRr3XtK2pfrTU6P/+cIajSkhMZSdbadaCt5Gzfgc7Lw611a3R+Hta8fLy6d8O1WTOSp00jb99+PCO6YKpWHafgYCzp6ShnZ3Kjokj77jucatSg2ksv4dWrpxzcFaIySVu4kIR33wOzbZhCB1VHB9fGkJsG+49Q6OdCUFAKhS2ciDHUwApstTblU8udeDibeLFXYx7tFAqAVYPRoEjMyONEWi5p2QVsOJRMkJcLg7rUw9lU8qW5ss3ZmAwmXIy24wF/J/zN9/u/59djv+JmcqO+T33qeNXhjoZ3cH2t6y+6rQOnMvli/RGyCyy4mozU8nXluR4NMRnLupak4xWmpWH08EA5O1/VdiTxC1EOWPPySPxwAvn792M1F5D3z05MDRtx/MFnWBJ5gACng/Q3redawxGsZoXBSbOWtjxjHkqdIH+Cfd3wdnOiR9Nq9GxWHRdTyV7RWZSYjBjqeNU50+vMMecQlxVHVFIUH2//mMyCTIa3GU50cjS/HfsNgK51uvJBlw9wd3Iv9fjEhUniF8LBLKdPEzNoMHk7d2Lw88NssZAa7ErbprtRTgo3VQBAtks1jvt1xP3G16hbuzbK1Zs8swUXk6HYX/nzLflM3TGVnck7CfUO5fb6t9PEvwkmgwln4397kWl5aayKWUWhtZCanjUJDwxnV/IuVsWsYvHBxVR3r46TwYmk3CQsVsuZ89LdTG7kFuae2U6PkB7cWu9Wrq91PR5OHiXQauJqyJW7QjiA1pqcv/4iZeZMsjdtBgUuXbypFnwUT3KwYGCfTxecXT2o1rw1hHQgza8Orlip7lGTdfFbySnMoa53XUK9Q4nPjueXI79wMuskfq5+7ErehUEZ6FanG/0a9mN/6n52p+zmp8M/cSj9EADbTm1j8cHFANTyqMXIjiPJt+Sz/dR21sau5XjG8Yu+hyC3IPxc/VAomgc2x8vZC6u20jygOXc1vIuMggwOpR+irnddqrlXK/U2FVdPevxClAJdWEj6Dz+QNn8B+Xv3YvTzo9BLERJ2kJPVgzAbXAj0ciPw4blkewfyzB/PsDN556U3XEyeTp6Mun4Uver2Ij0/nUnbJrEqZhUZBeeeJxnsGYyviy8danaga52u7EzaiVKKuKw4WlVrRdOAptTxqlNicYmyJUM9QpSBwtRUsjduJO3b78jdtg2Xhg1xvec+tias547sb/jDvTfV7/uMZsE+5BRmMXPnTObvnU+BtYA+9foQ7BlMiHcIqbmpbDi5gdvq30YD3wb8k/QP606uI8A1gCEthwBw7PQxvJy9qOdbj/Wx6zmQdgBPZ09qedbixpAbi7zoZ0/KHk5knsBsNdOmWhtqetYs6yYSZUgSvxClLGP5ck4OfxEAg5cXXk88QJTlBP4p2+lg2cYR73bUenY5O5Ijmb93PgfTD3Iy6ySN/BoxpOUQuod0d/A7EJVNmY/xK6VmAX2ARK11+HnPvQR8CARprWXOXVGhFaalkfb1PFI+/xyXBnXxa+eNmykK1/i3+HfepH+C2rG1c39W/z6Q6ORoAt0CqelRk+dbP89NoTdd8XnaQlyJ0jy4OweYAsw9e6FSqg7QE4gpxX0LUWq01mRv2AhKkfr1XNt9iwWDjxN1mv+Fk9VKXr4Tv6mO0PUlcn0OM3LnFIiaAsCt9W7l+dbPU8OjhoPfiaiqSnPO3XVKqdAinpoEvAIsLa19C1FazAkJnF76E0mTJgGgnJ3wb+WCl+9xUrw9eMvjBla416ZX445ENA5i8o4PiTseh1EZebfTu9wYcqOc2y4crkxP51RK3Q6c1Fr/I19tRUWizWYSJ31M6ty5UFiIc1gYPh0b4H16Hof9PBhr6sSfNY8Ah4HDrEhay4okcDY4c3v92xnUYhChPqEOfhdC2JRZ4ldKuQNvAL2Kuf5gYDBASEhIKUYmxMXlHzzIkdtuB8C798349bwOt9y1qJ1fsaSmD6OCfIAjADzS/BFur3878dnxmK1mWgS2kHPbRblTqmf12Id6lmmtw5VSLYA/gRz707WBOKCd1jrhYtuRs3qEI2itSZs/n6SPJmDNySMgPI+gVmbSLdnEOJmY7dmQP7yyMCjFi22Hc0eDO/Bx8XF02EKc4fArd7XW0cCZro9S6hjQVs7qEeVR9l9bSXjnHQqOHMHVr4Dg7mmo2qGsBN71spJhsgCZdAjqyac9R8u4vahQSvN0zgVAVyBQKRULjNJaf1la+xOipGStX8+JJ59EmRSB4Rn43tScUc4Psjh1I87+m1DaiTDXDrx6/eN0qnOdo8MV4rKV5lk9913i+dDS2rcQVypz1SpinxmCs7eFkJ7ZHGz+ML0TXMn1+xhnfzMtAzrxWa8JeDpfYB5bISoAKdImBFBw7BgJY8eSvXYdLn6a4IhsFnX5hrei1uJacxHN/FoysuMrtAhq4ehQhbhqkvhFlaatVpImTybls+kAmK71pkbDIwywvMnOzQfxDFtKm+rt+LzXjCue8FqI8kb+kkWVpbUmfsTrnF66FOcbe7HLO4m+zr8w2vwATTu0ITHrddyc/Jhww3hJ+qJSqXpzmgkBFMSeJH7kSE4vXYp7t5Z4BPxMX+dfOFn7Vl54fRzJbl9h1rnM6DmDALcAR4crRImSboyocnK27yDmiSfQOTnosOqEVFtOpG7EwfDnqHfTnTyy6nH2pe7j7Y5v08CvgaPDFaLESeIXVUry9BkkffwxAHktgmnZ5G/WGttjvuMLnPyO0PenflisFl5q+xL9GvZzbLBClBJJ/KLKyPj1N5KmTMHt2mtJaGmiQ/7PbHXrQtOn5/HB9nf5fcfv1PCowdjOY2lb4z8XOwpRaUjiF5VeYVoaCe++S+aKXzGE1GVf6yBuzp3LVt9uRHW9lU/WDyE6OZpBLQbx1LVPFTkZuRCViSR+UakVJidzfOAjFBw+jLFzBL8FGxiaO5flnh2YFWZi/z+f4uXsxZjOY7it/m2ODleIMiGJX1Ra1txcTjz9DOa4OAI+ncK3kb/wdMEcptZtyxfGRArT47g59GZebfcqgW6Bjg5XiDIjiV9USlpr4t94g7xdu4h7dCCnN7zOMMM+ltRpw3RDIj3q9OCFNi9Q17uuo0MVosxJ4heVUvK0aWQsX8GxLh3plT0Wo0GzuHZvPnA5REv/loyPGC9j+aLKkgu4RKWTOu8bkidPIbVZfbrV/Il4j6bsfeRnxroexMvFm0ndJknSF1WaJH5RqaQtXMip0aNxauBHx+brSfFqwBcdbuCetUPwcvZi9k2zZTxfVHky1CMqjcLUVE69PxZDiC/1Wu1mgUsf4iJasnjfXALdApnXex7BnsGODlMIh5PELyoFXVDAyWHPYc3Po37z43zk052vg6LR+3ZyW73bGN15NAYlX3CFAEn8opJImvYZOZGRBHdI49uwznzvH4un0ZMR7UbQp14flFKODlGIckMSv6jQdEEBSdOmkTJ9Bj6hOXx+bWsWBSRQw70Gs2+W8XwhilJq332VUrOUUolKqV1nLftQKbVPKbVTKfWDUsq3tPYvqoaUOV+RMn0G2q+QL7pWY37gKUK86/J5r88l6QtxAaU56DkHuPm8Zb8D4Vrra4ADwIhS3L+o5MwJCSRNnUJiqIUHB7uwsGYedb1DGB8xnhoeNRwdnhDlVmlOtr5OKRV63rKVZz3cAvQvrf2Lyk0XFrJ72GMoSwHv3OJMTacWfHzruzTwbSDj+UJcgiNPc3gMWHGhJ5VSg5VSkUqpyKSkpDIMS5R3244ms+6u23DZeZQfOytaBw3ilwcX0NCvoSR9IYrBIYlfKfUGUAh8c6F1tNYztdZttdZtg4KCyi44UW7lmS1M+G0/B158lGr7j7Gws6LWg08w4f7nHB2aEBVKmZ/Vo5QaCPQBemitdVnvX1Rc41bsI+637+m99yCbmxhwefwBHmsvSV+Iy1WmiV8pdTPwKnCD1jqnLPctKraoE+n8vvpvpv/9PXlOinX3NOCL9q9iNBgdHZoQFU5pns65ANgMNFZKxSqlHgemAF7A70qpKKXU9NLav6g8Ci1Wxi7exJR/JmLKgKU3evD+7dMxGeQyFCGuRGme1XNfEYu/LK39icpJa82w+ZG8s+8ldJzm624GHnj9K2p51nJ0aEJUWFK8RJRru2LTqbd3BoXRZpK9wfv+e2ke2NzRYQlRoUniF+WW1WIhY8Fj3BK7EmOKiVU3VefZ9i84OiwhKjxJ/KLcipr5JLX/2QpbPTlSx4mHXvgCT2dPR4clRIUnR8dE+WO1EvPtCwT9+DtZx705XNtA8znzqeffwNGRCVEpSI9flC/pMWROe5S06b+QddydjU0Vpk9HUz843NGRCVFpSI9flB8phyn8tBuHf3bDJceJnfWM6FFD6d3sTkdHJkSlIolflA+7fyRr5lD2b/LAVKAY99g1TB8+BzeTm6MjE6LSkcQvHG/dBFJmfETiNl/cgY9uDuPDp2dJ0heilEjiF44VNZ+c78cRHxXEnrqK6Z0bcEPLsVTz8nB0ZEJUWpL4heNELSB31jCOrQsixROmdr6Ga+q/zIhbmjo6MiEqNTmrRzjG+o/gx6eIP1iHTCcDo+6rhovX40wa0Apnk/xZClGa5D9MlL2YLfDnu6R430D+0TyWXaeISb+XMXe0wWSUP0khSpv8l4mylXwQFj4Kzp5s3JxMjgv8WO0+HmzVhetC/R0dnRBVgiR+UXb2LYcZN6DzM5nv3p2G0Wn80LwJPZvfytu3SeE1IcqKHNwVZePvL+GX4VA9nEnV29D+/d+JDXTn10ZP8OdtzTEYZK5cIcqK9PhF6YteZEv6dTvz542vETbtd9zNJsaFD+LNvi3xcXdydIRCVCmS+EXp0Rq2z4UfnoTgNhzpO5G/PnmXJrEwvUU/rut5PXe0CnZ0lEJUOaU59eIspVSiUmrXWcv8lVK/K6UO2n/6ldb+RTnw13T4aSgEtyW5/xdMnTSQO//I4u+aYRxv050XezV2dIRCVEml2eOfA9x83rLXgD+11g2BP+2PRWV0dB2sfBMa3Uzugwt5edM73LPsNMd8AlnZ/1WWDu1MkJeLo6MUokoqtcSvtV4HpJ63uC/wlf3+V8AdpbV/4UCpR2DB/RDQkNzbPuH5dS+TH7kN71zY3Pke5jzVBReT0dFRClFllfUYf3WtdTyA/We1C62olBqslIpUSkUmJSWVWYDiKmkNSwaDtsCDi/hw10w2ndzIE9tqkmVypfMDt8lFWkI4WLn9D9Raz9Rat9Vatw0KCnJ0OKK4dsyD2L+h57tEF6Sx8MBChsW1p+aBWFZ07EePlnUdHaEQVV5ZJ/5TSqmaAPafiWW8f1GaDv0Jy56Hel2xtHqIj7Z9RFC2M9d8u4N9AWHc995zGOV8fSEc7pKJXylVXSn1pVJqhf1xM6XU41e4v5+Agfb7A4GlV7gdUd6kHIbvH4agJnDP13y5dy7bEiIZ+IMfbtZC2n02kYY1vB0dpRCC4vX45wC/AbXsjw8Az1/qRUqpBcBmoLFSKtb+YTEO6KmUOgj0tD8WlcGf79p+3v89W9P2MS3qM3pE1aXdiZP4DBlK8DVNHBufEOKM4pRsCNRaf6+UGgGgtS5USlku9SKt9X0XeKrH5QQoKoD4f2DPjxDxChavGry36mnC4r146I9Yshs1p8ngxxwdoRDiLMXp8WcrpQIADaCU6gCcLtWoRMWhNawaDa4+FLQbxKDfB3Ei7QgP/6wxuntw7edTUUY5dVOI8qQ4Pf7h2Mbm6yulNgJBQP9SjUpUHKvHwMGV0Gs070R9wvaTW3lhQSBNkk9Ra8IEnKpXd3SEQojzXDTxK6WMwA32W2NAAfu11uYyiE2Ud3uWwroPocXdHGjci5+W9efpHwJod+IUfi+9hE+fWx0doRCiCBcd6tFaW4C+WutCrfVurfUuSfoCgIRo+HEI1GqNpc8nPPvnq3TYA90OJuL5+CBqPHGlJ34JIUpbcYZ6NiqlpgDfAdn/LtRaby+1qET598fbYDDC3XOYve97/PYdZMgvCqfwcGq/MMzR0QkhLqI4if96+893z1qmge4lH46oEHYuhEN/wI3vcECb+eOHj3nzeysqoBp1p05FmWR+HyHKs0v+h2qtu5VFIKKCMOfaevuBjaDdIKZ89zJDlxWQHVCdtkuXYPKXeXOFKO+Kc+Wuj1Jq4r8F05RSHymlfMoiOFHO5KbB3L6QEQs3j+O7v9bS97PVuBSYaDZ9miR9ISqI4pzHPwvIBO6x3zKA2aUZlCiH9i6DT1rCib/glvFsIpykj0dSLR38P/0U7+bNHB2hEKKYijMYW19rfddZj99RSkWVUjyiPNr7M3z3INRsCbd8QIFzKCn330WPuBySb+tKi64yGihERVKcHn+uUqrzvw+UUp2A3NILSZQreafhp2HgEwKPr0TXakvU4MHUTkphWZ96dH7/U0dHKIS4TMXp8T8NfHXWuH4a8EipRSTKD63hz/cgNxVunwwmF2LHvY/XgYNM7uPOG6O+QDk5OTpKIcRlKs5ZPVHAtUopb/vjjNIOSpQTf02Hvz+H9k9B0z6k/rqcrDlfs7KlgfC7xhLsVdPREQohrkBxzup5Xynlq7XO0FpnKKX8lFKjyyI44UBZibZSyw1vgpvGkpORyp53X+NIdVga0YenO/R0dIRCiCtUnDH+W7TW6f8+0FqnAb1LLSJRPqx8Ewrz4ab3seTksOuu2/BLMzMvvBNjbnoZpWQmLSEqquIkfqNSyuXfB0opN8DlIuuLim7vz7DzO+jwNGaLF5ED+uARm8rY3o1xu+5JOtYPdHSEQoirUJyDu/OAP5VSs7GVangM+KpUoxKOk7gXFj4KwW3JMnQipmdPPM1mvrijMf+4PM7y25s7OkIhxFUqzsHd8UqpncCN2Moyv6e1/u1qdqqUegF4AtsHSTTwqNY672q2KUpAfhYsGQxO7uS2eIsTTzxLfJCB6X0D+fvUQJ5q35A6/u6OjlIIcZWKc3DXA1iptX4JmAm4KKWu+Bw+pVQwMAxoq7UOB4zAvVe6PVGCVr8PCTvRvScS9+54snyceWOAle0Z9+Dt4s6TEfUcHaEQogQUZ4x/HeBqT9h/AI9im4D9apgAN6WUCXAH4q5ye+JqJUTDX59Bm0dJWhdPwZEjzOySR2p2V9ytjfjuyY74eTg7OkohRAkoTuJXWuscoB8wWWt9J3DFhVm01ieBCUAMEA+c1lqv/M9OlRr8b2G4pKSkK92dKA6tYfnL4OZHttetJH/2GdvrK9b63UpN6x1sGdGDpjW9HR2lEKKEFCvxK6U6Ag8Av9iXXXHBdaWUH9AXCANqAR5KqQfPX09rPVNr3VZr3TYoKOhKdyeKI3ohxGxGd3+LuE+mkuytmNQzjC41+vPTkAg8XKS+vhCVSXES/3PACOAHrfVupVQ9YPVV7PNG4KjWOsk+jeMS/j/Ziyhr2Snw6wio1Yr0w24U7t3PwusN6IIBTLy7FT7uUpJBiMqmOGf1rMM2zv/v4yPYDs5eqRigg1LKHVuxtx5A5FVsT1yNjZMgJ5nMBm+S8Prb7AtWrKrdjk9uvkmSvhCVVJl/h9da/6WUWgRsBwqBHdjOFhJlbddi2DQZS9P7OPLhdOKDFG/fHcT4LiO4sVl1R0cnhCglDhm81VqPAkY5Yt/CLmk//PgMhHRky4ZMfNMz+Oy+6oyLmMEtzRo4OjohRCkqzhi/qGz+PYvH5EJCXi/8f9/OT619GNB7Grc0a+zo6IQQpeySPX6lVFEzbZwGIrXWS0s+JFHq9iyFo2vJv+Y1Ut78gm0NFVs7Pc2rrZs6OjIhRBkoTo/fFWgJHLTfrgH8gceVUh+XWmSidBTk2CpvVg9n95LtZDtrpnVuxcR7+mMwSMVNIaqC4ozxNwC6a60LAZRSnwErgZ7Y6uyIikJr+P0trKknOOx6M26RvzC/kzdj7xhHWKCHo6MTQpSR4iT+YMAD2/AO9vu1tNYWpVR+qUUmSt7q9zGv+ZKjWxpiSfqF6LqKawZ/SLfGdRwdmRCiDBUn8Y8HopRSa7BV54wA3rcXb/ujFGMTJSlxL4W/TeDI2hBysvP56hYDnn0eYnT7CEdHJoQoY8W5gOtLpdRyoB22xP+61vrfomovl2ZwouRYfnmbY38GkZdrZXx/F1JaBLL0huccHZYQwgGKc1bPT8AC4CetdXbphyRKmt69jJNfbaUg25XRva9lX71/+LbrR7iZ3BwdmhDCAYpzVs9HQBdgj1JqoVKqv1LKtZTjEiWk4PA+4l55mewEV2a0b8n+a6LpHdab5oEyk5YQVVVxhnrWAmuVUkagOzAImAVInd5yLu/AAY71648uhK31arOq6y66BEcwqqNcNC1EVVaskg32CdZvAwYArZE5d8s986lETgwajDIVsrenB9Na5xPqGcpHXSfIEI8QVVxxxvi/A9oDvwJTgTVaa2tpByaunDabiX/9dQpTk9h9Ww7vNXKhhpsbE26QpC+EKF6PfzZwv9baAqCU6qSUul9rPaR0QxNXQmtN3IjXyd64kW1dC/igsQ9dgrswtssYfFx8HB2eEKIcKM4Y/69KqZZKqfuwDfUcxTZ5iihntNbEv/EmGcuWcap1IR90dKdLYD+m9ngbpaQcgxDC5oKJXynVCLgXuA9IAb7DNv9utzKKTVym00uXcnrJEtwa5TCquwdhrg2YfMtbkvSFEOe4WI9/H7AeuE1rfQhAKfVCmUQlLltBbCyn3n0Hl2oWPuzlRrqTM1N7vIfRYHR0aEKIcuZi5/HfBSQAq5VSnyulemC7cleUM4WpqZx44gm0OY+N3ays83Li+TbPER4Y7ujQhBDl0AUTv9b6B631AKAJsAZ4AaiulPpMKdXranaqlPJVSi1SSu1TSu1VSnW8mu1VZbqggJPDnqMg9gSeEal8FObNddU7MLD5QEeHJoQopy555a7WOltr/Y3Wug9QG4gCXrvK/X4C/Kq1bgJcC+y9yu1VWYkffUROZCTV26YytEUYJpOBdzq9hUHJ5GpCiKJdVnbQWqdqrWdorbtf6Q6VUt7YKnx+ad9mgdY6/Uq3V5WlL15C6tyvcWtiYFlzDw65ZTO8zXDqeEmZZSHEhTmiW1gPSAJmK6V2KKW+sJd4PodSarBSKlIpFZmUlFT2UZZjuqCAUx9+SPwbb+BU2wW38AQ+CfLmmsBruLfJvY4OTwhRzjki8ZuwlX34TGvdCsimiKEjrfVMrXVbrXXboKCgso6xXEv67DNSv5yFc4vauHQ+zs0NamMxWBndebQM8QghLskRWSIWiNVa/2V/vAjbB4Eohtzdu0mZ+TmGiA7UbraNodXDKFRWnmv9HGE+YY4OTwhRAZR54tdaJwAnlFKN7Yt6AHvKOo6KyBwXx8nhwzH5++NffQPzvAI57FbAiHYjeDT8UUeHJ4SoIIpVnbMUDAW+UUo5A0cAyVqXUJiaSsygwVhS0/C5tymHC/bzaVAN2lZvzYDGAxwdnhCiAnFI4tdaRwFtHbHviih7yxZihw7DmptL7dfuI+74JJ6tWYsQ77p83O1juTpXCHFZ5EhgOVeYkkLsM0NQTk6EfjySzGOfMKh6TZxcfJjRc7pU3BRCXDZHDfWIYkqe9hnW/HzCZk8nd/ldPF0tgEwnZxbcMpNanrUcHZ4QogKSHn85lrlmDWnffIPvPXeTdnghr/i6cNTZiQk3TKKJfxNHhyeEqKAk8ZdTBbGxxL/6Gi6NGsGAPkyOW8QWd1deavMmPUK7ODo8IUQFJkM95ZC2WIh/bQTW/Hx8P/yIT5a/wM/+Htwbci8Pt7jb0eEJISo4SfzlUNq335ITGUm10aN5Ze1m9vscppH2ZETXEY4OTQhRCUjiL2fMJ0+S9MmnuHfswGyvxhxMe5g8pZjQ/SMpxyCEKBGSScqR/MOHOXpXf7BaiX34CZYcHkGqs5mxPq0IC5FxfSFEyZAefzmhLRbiX38DgFoLFnDv6lco9DjGS1kWbrxrkoOjE0Uxm83ExsaSl5fn6FBEFefq6krt2rVxcnIq1vqS+MuJpClTyP3nH2p9MI6X9i6l0OUgr6Sk8dBNk8FTqpOWR7GxsXh5eREaGioT2guH0VqTkpJCbGwsYWHFK9QoQz3lQMbKlaR8Nh2fu/rxT3hjNqV+xXW5Zh7waQrN7nB0eOIC8vLyCAgIkKQvHEopRUBAwGV985TE72DmxEQS3hqFa/Pm+L3xJq+sGosRzZiMPAx3zgBJKuWaJH1RHlzu36EM9TiQ1pr4N9/EmptLrQ/HM2jFZLKdt/NsWjo1+0wB/3qODlEIUQlJj9+B0ubOJXvdeqq99BJfpexlR+Y8embnMLjB3dCsr6PDExWA0WikZcuWNG/enGuvvZaJEyditVqveHuenp5FLn/kkUdYtGhRsbfz9ttvExwcTMuWLWnYsCH9+vVjz57/T7tRUFDA888/T/369WnQoAF9+vQhJibmzPNKKV588cUzjydMmMDbb7992e8nMjKSYcOGAbBmzRo2bdp02e+ppNu4a9euREZGAtC7d2/S09OveFtXShK/g2T/tZVT4z/E88YexHbvwqfRowgr0LybY0L1fNfR4YkKws3NjaioKHbv3s3vv//O8uXLeeeddxwdFgAvvPACUVFRHDx4kAEDBtC9e3f+nT/79ddfJzMzkwMHDnDo0CHuuusu+vbteyahuri4sGTJEpKTk68qhrZt2/Lpp58C/038xVWabbx8+XJ8fX1LZFuXQ4Z6HMAcF8fJF17AuW5dao0bx6Clr2BUBUxOjMOz7wxwKbrXJcqvd37ezZ64jBLdZrNa3oy6rXmx169WrRozZ87kuuuu4+233yY/P5+nn36ayMhITCYTEydOpFu3bsyZM4fIyEimTJkCQJ8+fXjppZfo2rUrAC+++CKrV6/Gz8+Pb7/9lvPnvN62bRvDhw8nKyuLwMBA5syZQ82aNS8a24ABA/jll1+YP38+gwYNYvbs2Rw9ehSj0TaXxKOPPsqsWbP4448/6NWrFyaTicGDBzNp0iTGjBlzwe22aNGC9evX4+PjQ2BgIJMmTeLhhx/moYceYuDAgZhMJiZMmMCUKVOYPn06RqORefPmMXnyZADWrVvHxIkTSUhIYPz48fTv3/+y2virr766YFuuXLmSUaNGkZ+fT/369Zk9e/Z/vlGFhoYSGRlJVlYWt9xyC507d2bTpk0EBwezdOlS3Nzc+Pvvv3n88cfx8PCgc+fOrFixgl27dl00zkuRHn8Zs+bkEDt0GDo/n9pTpvDd4e2cLFzPw5nZ1K3TCcLvcnSIogKrV68eVquVxMREpk6dCkB0dDQLFixg4MCBlzzzIzs7m9atW7N9+3ZuuOGG//RszWYzQ4cOZdGiRWzbto3HHnuMN954o1ixtW7dmn379nHo0CFCQkLw9vY+5/m2bdueMxw0ZMgQvvnmG06fPn3BbXbq1ImNGzeye/du6tWrx/r16wHYsmULHTp0OLNeaGgoTz311JlvIV262C6IjI+PZ8OGDSxbtozXXnutWO/j7Da+kOTkZEaPHs0ff/zB9u3badu2LRMnTrzodg8ePMiQIUPYvXs3vr6+LF68GLB9KE6fPp3Nmzef+aC8Wg7r8SuljEAkcFJr3cdRcZS1uNdGkLd3L7WnTCE1sBrjVw3BRxl4KjsPHp4iZ/FUUJfTMy9tWmsANmzYwNChQwFo0qQJdevW5cCBAxd9rcFgYMAA21SeDz74IP369Tvn+f3797Nr1y569uwJgMViuWRv//y4tNZFnoXy7/P/8vb25uGHH+bTTz/Fzc2tyG126dKFdevWUbduXZ5++mlmzpzJyZMn8ff3v+DxirPdcccdGAwGmjVrxqlTp4r1PoqK9Xxbtmxhz549dOrUCbAd0+jYseNFXxMWFkbLli0BaNOmDceOHSM9PZ3MzEyuv/56AO6//36WLVtW7DgvxJFDPc8BewHvS61YWWT+8QeZK1cSNHw4LhE3cOuX72JxPcGIxGQ8Or0IviGODlFUcEeOHMFoNFKtWrULJieTyXTOwcmLfQs4P0FrrWnevDmbN2++7Nh27NhB27ZtadCgAcePHyczMxMvL68zz2/fvv0/Qy3PP/88rVu35tFHi56WOyIigqlTpxITE8OYMWP44YcfWLRo0Zke/aW4uLic896K4+w2vlBbaq3p2bMnCxYsKNY2z4/FaDSSm5tb7Jgul0OGepRStYFbgS8csX9HsKSnE//2O7g0aULAo48w+s8VpLn8wA15VnqbAqH9k44OUVRwSUlJPPXUUzz77LMopYiIiOCbb74B4MCBA8TExNC4cWNCQ0OJiorCarVy4sQJtm7demYbVqv1zJku8+fPp3Pnzufso3HjxiQlJZ1J/Gazmd27d18ytsWLF7Ny5Uruu+8+PDw8GDhwIMOHD8disQAwd+5cXF1dz/SQ/+Xv788999zDl19+WeR269SpQ3JyMgcPHqRevXp07tyZCRMmFJn4vby8yMzMvGSsF3N+G1+oLTt06MDGjRs5dOgQADk5OZf8tlUUPz8/vLy82LJlCwDffvvtVcX/L0f1+D8GXgG8LrSCUmowMBggJKRi94S11iS8NxpLejohn89kd3ISS06MpZqCMamnUQN/BpcLNoUQF5Sbm0vLli0xm82YTCYeeughhg8fDsAzzzzDU089RYsWLTCZTMyZMwcXFxc6depEWFgYLVq0IDw8nNatW5/ZnoeHB7t376ZNmzb4+Pjw3XffnbM/Z2dnFi1axLBhwzh9+jSFhYU8//zzNG/+36GuSZMmMW/ePLKzswkPD2fVqlVnDhSPHTuWl19+mcaNG5Obm0tQUBCbN28ucgjoxRdfPHPwtCjt27c/8wHSpUsXRowY8Z8PLIDbbruN/v37s3Tp0jMHd4vjYm18obYMCgpizpw53HfffeTn5wMwevRoGjVqVOz9/uvLL79k0KBBeHh40LVrV3x8SmCeba11md6APsA0+/2uwLJLvaZNmza6IktbuFDvadxEJ02bpi1Wi+4690F9zewWOnpMoNbbvnJ0eOIK7dmzx9EhVArx8fH62muv1TNmzHB0KOVSZmbmmftjx47Vw4YNK3K9ov4egUhdRE51RI+/E3C7Uqo34Ap4K6Xmaa0fdEAspS43ehcJo8fg3rEDAYMHM3TFhyRbo3g5LZPw+jdD64cdHaIQDlWjRg2ioqIcHUa59csvvzB27FgKCwupW7cuc+bMueptlnni11qPAEYAKKW6Ai9V1qRvPnmS4wMHYvTzI3j8eH45soa1SfNolefPg5lx0Os9R4cohCjnBgwYcOZMq5Ii5/GXEq01Ce+PhcJC6s79inRPxchNr2PIq8a0lIMYwu8Cv1BHhymEqIIceuWu1noNsMaRMZSWzBUryPrzT6q98grOdeowaPFAzNYCPi70wNNSCBGvODpEIUQVJT3+UmA5fZrEiZNwDgvD/5GB/H50DYeythOe14Ybk9ZCl+EQ2MDRYQohqiip1VMKTr0/FnN8PCFffsmJrFje2DAS8oL4PHM9BDSETs85OkQhRBUmPf4SlrlqFaeXLiXwycF4dGjPu5vHkWPO5c18P7xyE6HfTHAq+vJzIS6XlGUWV0ISfwkqTEsj/q1RuDRpQuBTT7Elfgt/JaynbnpDBqT+AR2egeDWl96QEMUkZZnFlZChnhJ06r3RWE6fJuSLz0mzZvHCqpdwyvdhQfafUPNa6D7S0SGK0rLiNUiILtlt1mgBt4wr9upVsSyzuDLS4y8hGStWkLF8OUHPPI1rkyaM3TSVTHMGY1Ny8HT1hQcWg5Oro8MUlVxVK8ssroz0+EtA/qFDxL/xJq7XXkPAE0+wPe4gv8YsoXl2EDflR0KfL8Ez6NIbEhXXZfTMS5uuQmWZxZWRxH+VLBkZxA55FuXuTu1PP6XQAEP+eBGD1cDHaTuhxd3Q4uKz+ghRUqpaWWZxZWSo5ypoq5W4l1+h4ORJan/yMU7Vq/P62rFk6aO8dzqPmu5BcMt4R4cpqoiqWJZZXBnp8V+F5ClTyFq7lupvjcS9TRvm7v6aX08spMnpYG4/vRkeXAzu/o4OU1RiUpZZXAl1oa+D5Unbtm11ZGSko8M4R+YffxD77FB8+vWj5pjRbIzbyDN/DEFl1WVzWiTuodfDAwtlKsVKbO/evTRt2tTRYVR4CQkJ3HzzzTzzzDMMHjzY0eFUWEX9PSqltmmt256/rvT4r0D+4cPEvfoaruHh1Bj1FqdyTvH6+tcxFtZkdLoVN10IvcdL0heiGKQsc9mTMf7LpAsLiXvlVZSLC7Unf0qGzuXJ358kqyAf35gbuNW8HtVxCPjXc3SoQghRJOnxX6bUuV+Tt3s3wR9Pwhzow5CVg4jJiCUv5mEWun8PFi+4fqijwxRCiAuSxH8ZMn79jaRJk/Ds1g2vm25i2OphRCfvIif2Ad6xbqV+7i6460s5oCuEKNdkqKeYcv/5h5PDh+PSsCG1xr7Pb8d/Y82JNeQn3sRgVwsPWJdBuyflnH0hRLknib8YCtPSiB06DFP16oTM/YpUZzNvb3wH8kPoRFNezpsMtdtBr9GODlUIIS6pzBO/UqqOUmq1UmqvUmq3UqrcF6c/9f5YClNTqTN1ClZ3F15c8xrZBXkEpvdnhvNUlLMH3DMXTM6ODlVUMZcqy7xhwwbatWtHkyZNaNy48Zn6PWArnezu7k5iYuKZZRcqyywqF0f0+AuBF7XWTYEOwBClVDMHxFEsmatWkfHzzwQ+9RSuzZox9q9x7EjaijW5Hz8Hr8Yp/Qjc9Tl4F69eiRAl6WJlmRMSErj//vuZPn06+/btY+PGjcyaNYsffvjhzOsDAwP56KOPHBW+cJAyP7irtY4H4u33M5VSe4FgYM9FX+gAefv2ET/yLVwaNyZw8CD+OPYnCw98T0FKBHObh+C5dQJ0eRHqdXV0qMLBPtj6AftS95XoNpv4N+HVdq8We/3zyzJPnTqVRx555MyVuYGBgYwfP56RI0dy5513AvDYY48xZ84cXn31Vfz95aSEqsKhY/xKqVCgFfBXEc8NVkpFKqUi/528oSxlbdzI8fsfQJlMBH80gZTCDEasH4Ulrxbv1L+R9ttfhVqtodPzZR6bEBdydlnmf0svnO380seenp489thjfPLJJ2UdqnAgh53OqZTyBBYDz2utM85/Xms9E5gJtpINZRlb/qFDnHxhOE516lBn5kwKA7wYsPABcguzucl7GAMOvQ4eQXD/9+DqfekNikrvcnrmpe1S5Y/PN2zYMFq2bHnOVIeicnNIj18p5YQt6X+jtV7iiBguxBwXR8xjj6NcnKk9ZTLGaoHc/+MLnMo/xLXOTzHRsAyVdQru+Upq7Ity5+yyzM2bN+f8Glfbtm2jbdtzS7f4+vpy//33M23atLIMVThQmff4la0L8iWwV2s9saz3fzHmxERin3seS1YWod8uwLlOHYb9+gGHsjdSz3gPc30Po/5eCt3flLlzRblzflnmIUOG0L59e/r160fLli1JSUnhjTfeYNy4/04aM3z4cK677joKCwsdELkoa47o8XcCHgK6K6Wi7LfeDojjHJaMDE48/gT5hw9T6/0xuDZqxNx/VrAqYT4+lvYsCm+E8e8ZtgnTI152dLhCAP8vy9y8eXNuvPFGevXqxahRowCoWbMm8+bNY/DgwTRu3JhatWoxbNgwbrjhhv9sJzAwkDvvvJP8/PyyfgvCAaQsM2AtKODEE4PI2bGDkBnT8bj+er7YsolP9j6LsvjzU8QoQhfeY5swfeDPYHQqtVhExVHRyjJPnTqV6dOns27dOvz8/Bwdjihhl1OWucpfuautVuJfG0HO1q3Uev99PK6/nq//3s6k6Ncw4sqciA8I/fU5cPaE/rMl6YsKa8iQIURHR0vSF1KkLfHDCWQsX07Qi8Pxua0P30f9w7h/nsfklM+siPG0XvEMZMbDg0vkIi0hRKVQpRN/2sKFpM6ejd/99xPwxBMs3RXNu5HPYjIVMKvdSFovfxnSY2wzadXt6OhwhRCiRFTZxJ+9ZQsJ776HR6dOVH99BEt3R/PmliEYjAXMavgAbZY8Ac7utqQf1sXR4QohRImpkok/Nzqa2CHP4lw3hFofTeCDNRv4+tjrGI0WZgX3os3vI6FOB9u5+l41HB2uEEKUqCqX+PMOHCDmiUEY/fwInjGToauWsS5tCi5OJuaF3EqzdROg8a3QfxY4uTo6XCGEKHFV6qye7M2bOX7vfRicnfGeOo3ev01iQ+YH+Dr7s8SjPs3WjofQLtBvhiR9USGUl7LMTzzxxJkaQO+///6Z5ceOHSM8PPySr3/77bcJDg6mZcuWNGzYkH79+p1TU+hyrVmzhj59+gDw008/FXnRWlVWZRJ/1tq1nHj6GZyCg0mdMIZb1r9MkvFXWnlGsNxcSOiuHyHiFXh4Kbh4OTpcIYqlvJRl/uKLL2jWzFZd/ezEfzleeOEFoqKiOHjwIAMGDKB79+6URIHG22+/nddee+2qt1OZVPqhHm21kvTJp6R88QXOjRoy5+Hr+GH3y2As4KnAOxmy62sw59jmypVpE8UVSnj/ffL3lmxZZpemTajx+uvFXr+0yjJ///33bNmyhYkTJ/LJJ5/wySefcOTIEQ4fPszAgQPZsGEDXbt2ZcKECSxatOicq4nHjBmDxWJh0KBBbNq0ieDgYJYuXYqbm9tF38uAAQP45ZdfmD9/Ps899xyhoaFERkYSGBhIZGQkL730EmvWrCE7O5uhQ4cSHR1NYWEhb7/9Nn379j1nW3PmzCEyMpIpU6bwyCOP4O3tTWRkJAkJCYwfP57+/ftjtVp59tlnWbt2LWFhYVitVh577DH696+cOaFS9/i11UrCO++SMmMG+T3aM+i2FH7IWICrtQ4za/ZmSORk8KoJj6+UpC8qhdIoyxwREcH69esBWL9+PQEBAZw8eZINGzbQpcu5Z7yNGzfuzLeQb775BoCDBw8yZMgQdu/eja+vL4sXLy7We2ndujX79l38w3TMmDF0796dv//+m9WrV/Pyyy+TnZ190dfEx8ezYcMGli1bduabwJIlSzh27BjR0dF88cUXbN68uVgxVlSVusef+MF40r/7jpg7ruOVJpGY84NoY3maOablGLdMhiZ94M4Z4CLTzYmrczk989JW0mWZa9SoQVZWFpmZmZw4cYL777+fdevWsX79evr163fJ7YeFhdGyZUsA2rRpw7Fjxy7rfVzMypUr+emnn5gwYQIAeXl5xMTEXPQ1d9xxBwaDgWbNmnHq1CnAdizk7rvvxmAwUKNGDbp161asGCuqSt3jP9IihN+7V+elJtuxZjVgfE5N5ia+hzFuG9w8Du75WpK+qFRKqyxzx44dmT17No0bN6ZLly6sX7+ezZs306lTp0vG5OLicua+0WgsdgXQHTt2nKk9YzKZzhy0zsvLO7OO1prFixcTFRVFVFQUMTExl6yfdHY8Z39IViWVOvGPzYzkyzY59E6uw7a0TfQ5/ROq+Z3w5Dro8DQYKvXbF1VMUWWZ58yZQ1RUFMCZsswjR478z2uHDx/OjBkzLpiUIyIimDBhAhEREbRq1YrVq1fj4uKCj4/Pf9Z1cnLCbDZf1XtZvHgxK1eu5L777gMgNDSUbdu2nXnuXzfddBOTJ08+k7h37NhxRfvr3Lkzixcvxmq1curUKdasWXNV8Zd3lTrzTfLwZH3sQT7I2oRzk5vg6U1wxzQIbOjo0IQoEWVVlrlLly6cOHGCiIgIjEYjderUoXPnzkWuO3jwYK655hoeeOCBy3ovkyZNOnM657x581i1ahVBQbbJjkaNGsVzzz1Hly5dMBqNZ14zcuRIzGYz11xzDeHh4UV+qBXHXXfdRe3atQkPD+fJJ5+kffv2RX6oVRaVuyxz9CI4th56jAJ3mUhalCwpy1y5ZGVl4enpSUpKCu3atWPjxo3UqFFxrty/nLLMlfrgLi36y9k6QtgNGTKEIUOGODqMcqtPnz6kp6dTUFDAyJEjK1TSv1yVO/ELIUQxVfZx/bM5arL1m5VS+5VSh5RSckmdqLAqwlCpqPwu9++wzBO/UsoITAVuAZoB9ymlmpV1HEJcLVdXV1JSUiT5C4fSWpOSkoKra/HrizliqKcdcEhrfQRAKfUt0Be48opMQjhA7dq1iY2NLZF6MkJcDVdXV2rXrl3s9R2R+IOBE2c9jgXan7+SUmowMBggJCSkbCIT4jI4OTkRFhbm6DCEuGyOGOMv6hry/3xX1lrP1Fq31Vq3/fdcXiGEEFfPEYk/Fqhz1uPaQJwD4hBCiCrJEYn/b6ChUipMKeUM3Av85IA4hBCiSnLIlbtKqd7Ax4ARmKW1HnOJ9ZOA42UQWmkKBJIdHUQ5Iu1xLmmP/5O2ONfVtEddrfV/xsorRMmGykApFVnUpdNVlbTHuaQ9/k/a4lyl0R6VukibEEKI/5LEL4QQVYwk/rIz09EBlDPSHueS9vg/aYtzlXh7yBi/EEJUMdLjF0KIKkYSvxBCVDGS+EuIUqqOUmq1UmqvUmq3Uuo5+3J/pdTvSqmD9p9+Z71mhL009X6l1E2Oi750KKWMSqkdSqll9sdVuS18lVKLlFL77H8jHatqeyilXrD/j+xSSi1QSrlWpbZQSs1SSiUqpXadteyy379Sqo1SKtr+3KdKqaLK4RRNay23ErgBNYHW9vtewAFsZafHA6/Zl78GfGC/3wz4B3ABwoDDgNHR76OE22Q4MB9YZn9cldviK+AJ+31nwLcqtge2Io1HATf74++BR6pSWwARQGtg11nLLvv9A1uBjtjqn60AbiluDNLjLyFa63it9Xb7/UxgL7Y/8r7Y/umx/7zDfr8v8K3WOl9rfRQ4hK1kdaWglKoN3Ap8cdbiqtoW3tj+2b8E0FoXaK3TqaLtga0qsJtSygS4Y6vVVWXaQmu9Dkg9b/FlvX+lVE3AW2u9Wds+Beae9ZpLksRfCpRSoUAr4C+gutY6HmwfDkA1+2pFlacOLsMwS9vHwCuA9axlVbUt6gFJwGz70NcXSikPqmB7aK1PAhOAGCAeOK21XkkVbIvzXO77D7bfP395sUjiL2FKKU9gMfC81jrjYqsWsaxSnFurlOoDJGqttxX3JUUsqxRtYWfC9tX+M611KyAb29f5C6m07WEfu+6LbdiiFuChlHrwYi8pYlmlaItiutD7v6p2kcRfgpRSTtiS/jda6yX2xafsX8uw/0y0L6/M5ak7AbcrpY4B3wLdlVLzqJptAbb3F6u1/sv+eBG2D4Kq2B43Ake11klaazOwBLieqtkWZ7vc9x9rv3/+8mKRxF9C7EfUvwT2aq0nnvXUT8BA+/2BwNKzlt+rlHJRSoUBDbEdrKnwtNYjtNa1tdah2Mpur9JaP0gVbAsArXUCcEIp1di+qAe2qUarYnvEAB2UUu72/5ke2I6HVcW2ONtlvX/7cFCmUqqDvR0fPus1l+boI9yV5QZ0xvZVaycQZb/1BgKAP4GD9p/+Z73mDWxH6fdzGUfkK9IN6Mr/z+qpsm0BtAQi7X8fPwJ+VbU9gHeAfcAu4GtsZ6xUmbYAFmA7vmHG1nN//EreP9DW3oaHgSnYKzEU5yYlG4QQooqRoR4hhKhiJPELIUQVI4lfCCGqGEn8QghRxUjiF0KIKkYSv6gSlFJjlVJdlVJ3KKUudtXsxbbRVin1aQnEMkcp1f9qtyPElZLEL6qK9thqJ90ArL+SDWitI7XWw0o0KiEcQBK/qNSUUh8qpXYC1wGbgSeAz5RSbyml6iulflVKbVNKrVdKNbG/Zo5Sarp92QF77SHs3xj+nVvgBqVUlP22QynlpWw+tNeZj1ZKDbCvq5RSU5RSe5RSv/D/Alz/1lRfa4/ht7Mu2x9mX3+nUurbMm00Ufk5+io2ucmttG/YyvhOBpyAjWct/xNoaL/fHltpCYA5wK/YOkYNsV1d6cq5VyH/DHSy3/fEVojtLuB3wAhUx1aeoCbQ76zltYB0oL89nk1AkH07A4BZ9vtxgIv9vq+j21BuletmKtmPESHKpVbYSmg0wVYj598qqtcDC8+auMjlrNd8r7W2AgeVUkfsrz3bRmCiUuobYInWOlYp1RlYoLW2YCu6tRbbN42Is5bHKaVW2bfRGAgHfrfHYMR2KT/YSjt8o5T6EVuJByFKjCR+UWkppVpi673XBpKxTfqhlFJR2Mb607XWLS/w8vNrmZzzWGs9zj5s0xvYopS6kaJL5V5oe9jX36217ljEc7di+8C4HRiplGqutS68yPaFKDYZ4xeVltY6yp7Y/50GcxVwk9a6pdb6NHBUKXU3nBmHv/asl9+tlDIopepjm0hl/9nbVkrV11pHa60/wFZ8rQmwDhigbHMNB2FL3Fvty++1L68JdLNvZj8QpJTqaN+mk1KquVLKANTRWq/GNpmNL7bhJCFKhPT4RaVmT8BpWmurUqqJ1nrPWU8/gO1A75vYxtu/xTa/KdiS8lpsY/VPaa3z1LlzWT+vlOoGWLANH60ACrDNgfoPth7+K1rrBKXUD0B3IBrbh9BasE3BaD+t81OllA+2/8eP7evMsy9TwCRtm6pRiBIh1TmFOI9Sag62g7iLHB2LEKVBhnqEEKKKkR6/EEJUMdLjF0KIKkYSvxBCVDGS+IUQooqRxC+EEFWMJH4hhKhi/gdAbZ6K2yjtMQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_scores(dddqn_scores, \"Double DQN with Dueling\")\n",
    "plot_scores(ddqn_scores, \"Double DQN\")\n",
    "plot_scores(dqn_scores, \"DQN\")\n",
    "plot_scores(dueling_scores, \"DQN with Dueling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check out the smart agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 13.0\n"
     ]
    }
   ],
   "source": [
    "env_info = env.reset(train_mode=False)[brain_name] # reset the environment\n",
    "state = env_info.vector_observations[0]            # get the current state\n",
    "score = 0                                          # initialize the score\n",
    "while True:\n",
    "    action = int(agent.act(state, 0.))\n",
    "    #action = np.random.randint(action_size)        # select an action\n",
    "    env_info = env.step(int(action))[brain_name]        # send the action to the environment\n",
    "    next_state = env_info.vector_observations[0]   # get the next state\n",
    "    reward = env_info.rewards[0]                   # get the reward\n",
    "    done = env_info.local_done[0]                  # see if episode has finished\n",
    "    score += reward                                # update the score\n",
    "    state = next_state                             # roll over the state to next time step\n",
    "    if done:                                       # exit loop if episode finished\n",
    "        break\n",
    "    \n",
    "print(\"Score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next Steps\n",
    "\n",
    "We can try a few things to further improve the agent:\n",
    "* fix the prioritized experience replay data structure and sampling logic to make it faster. We can reference the methodolgy [here](https://nn.labml.ai/rl/dqn/replay_buffer.html) and [here](https://github.com/facebookresearch/ReAgent/tree/main/reagent/replay_memory)\n",
    "* We can go one step further and try to implement the Rainbow model [here](https://paperswithcode.com/method/rainbow-dqn).\n",
    "* We can spend more time on finetuning hyper parameters. For the above runs, I basically juse used the same parameters I used in the exercise. It seems to work but we can definitely improve by more fine-tuning.\n",
    "* We can try more complicated network structure, eg, more layers, more nodes, try CNN or other structure."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
